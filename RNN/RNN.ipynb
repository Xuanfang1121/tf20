{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 情感分析\n",
    "- 利用循环神经网络搭建情感分析模型。循环神经网络RNN使用了文本的序列信息，准确率比前向网络要高。本次搭建的RNN模型如下图：\n",
    "<img src=\"images/network_diagram.png\" width=400px>\n",
    "- 将单词传入 embedding层，之所以使用嵌入层，是因为单词数量太多，使用嵌入式方式词向量来表示单词更有效率。在这里我们使用word2vec方式来实现.\n",
    "- 通过embedding 层, 新的单词表示传入 LSTM cells。这将是一个递归链接网络，所以单词的序列信息会在网络之间传递。\n",
    "- LSTM cells连接一个sigmoid output layer 。 使用sigmoid可以预测该文本是\"positive\" 还是\"negative\"情感。 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDB数据集介绍\n",
    "IMDB数据集有50000条数据集，训练集有25000条，测试集有25000条。数据label分为正负类，每类各占50%。这里采用keras的数据集中的imdb，每条数据已经做好了编码。label为0表示负类，label为1表示正类。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:  (25000,)\n",
      "test data shape:  (25000,)\n"
     ]
    }
   ],
   "source": [
    "word_nums = 8000\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=word_nums)\n",
    "print(\"train data shape: \", x_train.shape)\n",
    "print(\"test data shape: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 2, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 2, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 2, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 2, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 2, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 重新构建训练集与测试集\n",
    "x_train_new = []\n",
    "for i in range(len(x_train)):\n",
    "  x_train_new.append(x_train[i])\n",
    "for i in range(15000):\n",
    "  x_train_new.append(x_test[i])\n",
    "print(len(x_train_new))\n",
    "x_test_new = []\n",
    "for i in range(15000, 25000):\n",
    "  x_test_new.append(x_test[i])\n",
    "print(len(x_test_new))\n",
    "y_train_new = []\n",
    "for i in range(len(y_train)):\n",
    "  y_train_new.append(y_train[i])\n",
    "for i in range(15000):\n",
    "  y_train_new.append(y_test[i])\n",
    "print(len(y_train_new))\n",
    "y_test_new = []\n",
    "for i in range(15000, 25000):\n",
    "  y_test_new.append(y_test[i])\n",
    "print(y_test_new[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #数据集打乱顺序\n",
    "index = [i for i in range(len(x_train_new))]\n",
    "random.shuffle(index)\n",
    "x_train_new = np.array(x_train_new)[index]\n",
    "y_train_new = np.array(y_train_new)[index]\n",
    "\n",
    "index = [i for i in range(len(x_test_new))]\n",
    "random.shuffle(index)\n",
    "x_test_new = np.array(x_test_new)[index]\n",
    "y_test_new = np.array(y_test_new)[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 序列长度预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length:  2494\n",
      "min length:  11\n"
     ]
    }
   ],
   "source": [
    "max_length = len(max((x_train_new), key=len))\n",
    "min_length = len(min((x_train_new), key=len))\n",
    "print(\"max length: \", max_length)\n",
    "print(\"min length: \", min_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 高阶API介绍<br />\n",
    "tf.keras.preprocessing.sequence.pad_sequences(\n",
    "    sequences, maxlen=None, dtype='int32', padding='pre', truncating='pre',\n",
    "    value=0.0)\n",
    "    - sequences: list of list\n",
    "    - maxlen: 最大长度，整形，返回最大长度的list\n",
    "    - padding：填充方式，默认是pre，也可以选择post\n",
    "    - truncating：截断方式，默认pre\n",
    "    - value: 默认填充的值为0\n",
    "    - 返回numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape (25000, 300)\n",
      "x_test shape:  (25000, 300)\n"
     ]
    }
   ],
   "source": [
    "max_len = 200\n",
    "x_train_new = tf.keras.preprocessing.sequence.pad_sequences(x_train_new, maxlen=max_len, padding=\"pre\")\n",
    "x_test_new = tf.keras.preprocessing.sequence.pad_sequences(x_test_new, maxlen=max_len, padding=\"pre\")\n",
    "print(\"x_train shape\", x_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 搭建RNN模型\n",
    "   - lstm 网络\n",
    "   <img src=\"images/lstmcell.jpg\" width=600px>\n",
    "   - lstm的参数量计算\n",
    "       - lstm输出的大小为m，输入的大小为n，则参数量为4x((m+n)x m + m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(object):\n",
    "    def __init__(self, word_nums, embedding_size, max_len, hidden_units):\n",
    "        self.word_nums = word_nums\n",
    "        self.embedding_size = embedding_size\n",
    "        self.max_len = max_len\n",
    "        self.hidden_units = hidden_units\n",
    "    \n",
    "    def build_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.LSTM(self.hidden_units, return_sequences=True))\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.LSTM(self.hidden_units, return_sequences=False))\n",
    "        model.add(tf.keras.layers.Dropout(0.5))\n",
    "        # model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(2, activation=\"sigmoid\", kernel_initializer='random_uniform')))\n",
    "        # model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(2, activation=\"sigmoid\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "embedding_size = 50\n",
    "hidden_units = 16\n",
    "if not os.path.exists(\"./models/rnn/\"):\n",
    "    os.mkdir(\"./models/rnn/\")\n",
    "if not os.path.exists(\"./logs/\"):\n",
    "    os.mkdir(\"./logs/\")\n",
    "log_dir = \"./logs/imdbrnn_event-{}\".format(int(time.time()))\n",
    "## 加载rnn模型\n",
    "model = RNNModel(word_nums, embedding_size, max_len, hidden_units).build_model()\n",
    "## 加学习率衰减\n",
    "def lr_decay(epoch):\n",
    "    initial_lr = 0.01\n",
    "    drop = 0.5\n",
    "    epochs_drop = 20\n",
    "    lr = initial_lr * math.pow(drop, math.floor((1 + epoch)/epochs_drop))\n",
    "    return lr\n",
    "#model = model.build_model()\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.ModelCheckpoint(\"./model/imdb_rnn_lstm_new.h5\"),\n",
    "         tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)]\n",
    "         #tf.keras.callbacks.LearningRateScheduler(lr_decay)]\n",
    "\n",
    "history = model.fit(x_train_new, y_train_new, batch_size=batch_size, epochs=epochs, \n",
    "                    callbacks=my_callbacks, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.plot(history.history[\"accuracy\"], \"b\", linewidth=3.0)\n",
    "plt.plot(history.history[\"val_accuracy\"], \"r\", linewidth=3.0)\n",
    "plt.legend([\"acc\", \"val_acc\"], fontsize=18)\n",
    "plt.xlabel(\"epochs\", fontsize=16)\n",
    "plt.ylabel(\"accuracy\", fontsize=16)\n",
    "plt.title(\"accuaacy curve\")\n",
    "plt.savefig(\"./image/rnn_lstm_accuracy.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure()\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend([\"loss\", \"val_loss\"], fontsize=18)\n",
    "plt.xlabel(\"epoch\", fontsize=16)\n",
    "plt.ylabel(\"loss\", fontsize=16)\n",
    "plt.title(\"loss curve\")\n",
    "plt.savefig(\"./image/rnn_lstm_loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 评价模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test_new, y_test_new, batch_size, verbose=1)\n",
    "print(\"score: \", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(x_test_new[：3, :])\n",
    "result = result.tolist()\n",
    "final_result = []\n",
    "for i in result:\n",
    "    if i >= 0.5:\n",
    "        final_result.append(\"positive\")\n",
    "    else:\n",
    "        final_result.append(\"negative\")\n",
    "print(\"predict result: \", final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 搭建RNN模型-- GRU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gru模型\n",
    "<img src=\"images/grucell.png\" width=400px>\n",
    "- gru参数量计算\n",
    "- tf.keras.layers.GRU(\n",
    "    units, activation='tanh', recurrent_activation='sigmoid', use_bias=True,\n",
    "    kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal',\n",
    "    bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None,\n",
    "    bias_regularizer=None, activity_regularizer=None, kernel_constraint=None,\n",
    "    recurrent_constraint=None, bias_constraint=None, dropout=0.0,\n",
    "    recurrent_dropout=0.0, implementation=2, return_sequences=False,\n",
    "    return_state=False, go_backwards=False, stateful=False, unroll=False,\n",
    "    time_major=False, reset_after=True, **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(object):\n",
    "    def __init__(self, word_nums, embedding_size, max_len, hidden_units):\n",
    "        self.word_nums = word_nums\n",
    "        self.embedding_size = embedding_size\n",
    "        self.max_len = max_len\n",
    "        self.hidden_units = hidden_units\n",
    "    \n",
    "    def build_model(self):\n",
    "      model = tf.keras.Sequential()\n",
    "      model.add(tf.keras.layers.Embedding(input_dim=self.word_nums, output_dim=self.embedding_size, input_length=self.max_len))\n",
    "      model.add(tf.keras.layers.GRU(self.hidden_units, return_sequences=True))\n",
    "      model.add(tf.keras.layers.Dropout(0.3))\n",
    "      model.add(tf.keras.layers.GRU(self.hidden_units, return_sequences=False))\n",
    "      model.add(tf.keras.layers.Dropout(0.5))\n",
    "      # model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(2, activation=\"sigmoid\", kernel_initializer='random_uniform')))\n",
    "      # model.add(tf.keras.layers.Flatten())\n",
    "      model.add(tf.keras.layers.Dense(2, activation=\"sigmoid\"))\n",
    "      return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 50\n",
    "batch_size = 256\n",
    "embedding_size = 30\n",
    "hidden_units = 16\n",
    "\n",
    "if not os.path.exists(\"./models/rnn/\"):\n",
    "    os.mkdir(\"./models/rnn/\")\n",
    "if not os.path.exists(\"./logs_gru/\"):\n",
    "    os.mkdir(\"./logs_gru/\")\n",
    "log_dir = \"./logs_gru/imdbrnn_event-{}\".format(int(time.time()))\n",
    "## 加载rnn模型\n",
    "model = RNNModel(word_nums, embedding_size, max_len, hidden_units).build_model()\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.ModelCheckpoint(\"./models/rnn/imdb_rnn_gru.h5\"),\n",
    "               tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)]\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, callbacks=my_callbacks,\n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.plot(history.history[\"accuracy\"], \"b\", linewidth=3.0)\n",
    "plt.plot(history.history[\"val_accuracy\"], \"r\", linewidth=3.0)\n",
    "plt.legend([\"acc\", \"val_acc\"], fontsize=18)\n",
    "plt.xlabel(\"epochs\", fontsize=16)\n",
    "plt.ylabel(\"accuracy\", fontsize=16)\n",
    "plt.title(\"accuaacy curve\")\n",
    "plt.savefig(\"./image/rnn_gru_accuracy.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure()\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend([\"loss\", \"val_loss\"], fontsize=18)\n",
    "plt.xlabel(\"epoch\", fontsize=16)\n",
    "plt.ylabel(\"loss\", fontsize=16)\n",
    "plt.title(\"loss curve\")\n",
    "plt.savefig(\"./image/rnn_gru_loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test_new, y_test_new, batch_size, verbose=1)\n",
    "print(\"score: \", scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 搭建RNN模型-- CuDNNLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel(object):\n",
    "    def __init__(self, word_nums, embedding_size, max_len, hidden_units):\n",
    "        self.word_nums = word_nums\n",
    "        self.embedding_size = embedding_size\n",
    "        self.max_len = max_len\n",
    "        self.hidden_units = hidden_units\n",
    "    \n",
    "    def build_model(self):\n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Embedding(input_dim=self.word_nums, output_dim=self.embedding_size,\n",
    "                                           input_length=self.max_len))\n",
    "        model.add(tf.compat.v1.keras.layers.CuDNNLSTM(self.hidden_units, return_sequences=True))\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.compat.v1.keras.layers.CuDNNLSTM(self.hidden_units, return_sequences=False))\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Dense(2, activation=\"sigmoid\"))\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 64\n",
    "embedding_size = 200\n",
    "hidden_units = 256\n",
    "\n",
    "if not os.path.exists(\"./models/rnn/\"):\n",
    "    os.mkdir(\"./models/rnn/\")\n",
    "if not os.path.exists(\"./logs_culstm/\"):\n",
    "    os.mkdir(\"./logs_culstm/\")\n",
    "log_dir = \"./logs_culstm/imdbrnn_event-{}\".format(int(time.time()))\n",
    "## 加载rnn模型\n",
    "model = RNNModel(word_nums, embedding_size, max_len, hidden_units).build_model()\n",
    "model.summary()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\n",
    "             loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "             metrics=[\"accuracy\"])\n",
    "\n",
    "my_callbacks = [tf.keras.callbacks.ModelCheckpoint(\"./models/rnn/imdb_rnn_culstm.h5\"),\n",
    "               tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)]\n",
    "\n",
    "history = model.fit(x_train_new, y_train_new, batch_size=batch_size, epochs=epochs, callbacks=my_callbacks,\n",
    "                    validation_data=(x_test_new, y_test_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure()\n",
    "plt.plot(history.history[\"accuracy\"], \"b\", linewidth=3.0)\n",
    "plt.plot(history.history[\"val_accuracy\"], \"r\", linewidth=3.0)\n",
    "plt.legend([\"acc\", \"val_acc\"], fontsize=18)\n",
    "plt.xlabel(\"epochs\", fontsize=16)\n",
    "plt.ylabel(\"accuracy\", fontsize=16)\n",
    "plt.title(\"accuaacy curve\")\n",
    "plt.savefig(\"./image/rnn_culstm_accuracy.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure()\n",
    "plt.plot(history.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"])\n",
    "plt.legend([\"loss\", \"val_loss\"], fontsize=18)\n",
    "plt.xlabel(\"epoch\", fontsize=16)\n",
    "plt.ylabel(\"loss\", fontsize=16)\n",
    "plt.title(\"loss curve\")\n",
    "plt.savefig(\"./image/rnn_culstm_loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = model.evaluate(x_test, y_test, batch_size, verbose=1)\n",
    "print(\"score: \", scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
