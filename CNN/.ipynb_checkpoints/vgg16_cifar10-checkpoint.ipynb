{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. VGG网络\n",
    "vgg网络介绍，常用的网络主要是vgg16和vgg19。如下图所示。\n",
    "<img src=\"./images/vgg.png\" style=\"height: 60%;width: 60%; position: relative;right:10%\">\n",
    "下图展示vgg16网络的大小变化\n",
    "<img src=\"./images/vgg16_2.png\" style=\"height: 60%;width: 60%; position: relative;right:10%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. cifar10数据集介绍\n",
    "CIFAR-10数据集由10个类的60000个32x32彩色图像组成，每个类有6000个图像。有50000个训练图像和10000个测试图像。\n",
    "数据集分为五个训练批次和一个测试批次，每个批次有10000个图像。测试批次包含来自每个类别的恰好1000个随机选择的图像。训练批次以随机顺序包含剩余图像，但一些训练批次可能包含来自一个类别的图像比另一个更多。总体来说，五个训练集之和包含来自每个类的正好5000张图像。\n",
    "以下是数据集中的类，以及来自每个类的10个随机图像：\n",
    "<img src=\"./images/cifar10.webp\" style=\"height: 60%;width: 60%; position: relative;right:10%\">\n",
    "这些类完全相互排斥。汽车和卡车之间没有重叠。“汽车”包括轿车，SUV，这类东西。“卡车”只包括大卡车。都不包括皮卡车。\n",
    "airplane/automobile/bird/cat/deer/dog/frog/horse/ship/truck\n",
    "- 数据集下载链接\n",
    "http://www.cs.toronto.edu/~kriz/cifar.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 搭建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载cifar10数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (50000, 32, 32, 3)\n",
      "y_train shape:  (50000, 1)\n",
      "x_test shape:  (10000, 32, 32, 3)\n",
      "y_test shape:  (50000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)\n",
    "print(\"y_test shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可视化一张图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(x_train[135])\n",
    "print(y_train[135])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "means = np.mean(x_train, axis=(0, 1, 2, 3))\n",
    "stds = np.std(x_train, axis=(0, 1, 2, 3))\n",
    "x_train = (x_train - means) / (stds + 1e-5)\n",
    "x_test = (x_test - means) / (stds + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120.70748 64.150024\n"
     ]
    }
   ],
   "source": [
    "print(means, stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "y_test = tf.convert_to_tensor(y_test)\n",
    "## method 2\n",
    "# y_train = tf.one_hot(y_train, 10)\n",
    "# y_test = tf.one_hot(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 搭建vgg网络\n",
    "  - 卷积层\n",
    "  - 池化\n",
    "  - 全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGModel(object):\n",
    "    def __init__(self, drop_rate):\n",
    "        self.drop_rate = drop_rate\n",
    "    \n",
    "    def build_model(self):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(input_shape=(32, 32, 3), filters=64, kernel_size=(3, 3), \n",
    "                                         strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", name=\"conv1\"))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", name=\"conv2\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\", name=\"pool1\"))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", name=\"conv3\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", name=\"conv4\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\", name=\"pool2\"))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", name=\"conv5\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", name=\"conv6\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", name=\"conv7\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", name=\"conv8\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", name=\"conv9\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", name=\"conv10\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", name=\"conv11\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", name=\"conv12\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", name=\"conv13\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(512, activation=\"relu\", name=\"fc1\"))\n",
    "        model.add(tf.keras.layers.Dropout(self.drop_rate))\n",
    "        model.add(tf.keras.layers.Dense(256, activation=\"relu\", name=\"fc2\"))\n",
    "        model.add(tf.keras.layers.Dropout(self.drop_rate))\n",
    "        model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "        model.compile(optimizer=tf.keras.optimizers.SGD(0.01),\n",
    "                     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练\n",
    "   - 采用ImageDataGenerator对数据集做处理旋转，shift处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading model parameters from ./models/vgg/vgg_cifar10.h5\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 8, 8, 256)         131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 8, 8, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv7 (Conv2D)               (None, 8, 8, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv8 (Conv2D)               (None, 4, 4, 512)         524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv9 (Conv2D)               (None, 4, 4, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv10 (Conv2D)              (None, 4, 4, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv11 (Conv2D)              (None, 2, 2, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv12 (Conv2D)              (None, 2, 2, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv13 (Conv2D)              (None, 2, 2, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 7,099,722\n",
      "Trainable params: 7,091,402\n",
      "Non-trainable params: 8,320\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 781 steps, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "781/781 [==============================] - 525s 672ms/step - loss: 1.4688 - accuracy: 0.4375 - val_loss: 1.6759 - val_accuracy: 0.3751\n",
      "Epoch 2/3\n",
      "781/781 [==============================] - 516s 661ms/step - loss: 1.4279 - accuracy: 0.4623 - val_loss: 1.4860 - val_accuracy: 0.4358\n",
      "Epoch 3/3\n",
      "781/781 [==============================] - 518s 663ms/step - loss: 1.3815 - accuracy: 0.4799 - val_loss: 1.5397 - val_accuracy: 0.4146\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False) #\n",
    "datagen.fit(x_train)\n",
    "## 训练模型\n",
    "ckpt = tf.io.gfile.listdir(\"./models/vgg/\")\n",
    "if ckpt:\n",
    "    model_file = os.path.join(\"./models/vgg/\", ckpt[-1])\n",
    "    print(\"Reading model parameters from %s\" % model_file)\n",
    "    ## 加载模型\n",
    "    model = tf.keras.models.load_model(model_file)\n",
    "    model.summary()\n",
    "else:\n",
    "    vgg = VGGModel(0.3)\n",
    "    model = vgg.build_model()\n",
    "    model.summary()\n",
    "\n",
    "if not os.path.exists(\"./logs_vgg/\"):\n",
    "    os.mkdir(\"./logs_vgg/\")\n",
    "log_dir = \"./logs_vgg/vgg_cifar10_event-{}\".format(int(time.time()))\n",
    "my_callbacks = [tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)]\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=64), \n",
    "                    steps_per_epoch=x_train.shape[0] // 64, epochs=3, validation_data=(x_test, y_test),\n",
    "                    callbacks=my_callbacks)\n",
    "checkpoint_file = os.path.join(\"./models/vgg/vgg_cifar10.h5\")\n",
    "model.save(checkpoint_file)\n",
    "sys.stdout.flush() ## ubuntu 显示地让缓冲区的内容输出。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 测试模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试准确率为：  0.3971\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(x_test)\n",
    "pred_ = tf.equal(tf.argmax(result, 1), tf.argmax(y_test, 1))\n",
    "pred_ = tf.cast(pred_, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(pred_)\n",
    "print(\"测试准确率为： \", accuracy.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 显示模型结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载训练模型,对输入的图像做预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model load success\n",
      "[0]\n",
      "airplane\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "def read_image(data_path):\n",
    "    img = Image.open(data_path)\n",
    "    img = img.convert(\"RGB\")\n",
    "    r, g, b = img.split()\n",
    "    r_arr = np.array(r)\n",
    "    g_arr = np.array(g)\n",
    "    b_arr = np.array(b)\n",
    "    img = np.concatenate((r_arr, g_arr, b_arr))\n",
    "    img = img.reshape([1, 32, 32, 3])\n",
    "    means = 120.70748 \n",
    "    stds = 64.150024\n",
    "    img = img.astype(\"float32\")\n",
    "    img = (img - means) / (stds + 1e-5)\n",
    "    return img\n",
    "model_file = os.path.join(\"./models/vgg/vgg_cifar10.h5\")\n",
    "model = tf.keras.models.load_model(model_file)\n",
    "print(\"model load success\")\n",
    "image = read_image(\"./deer.png\")\n",
    "result = model.predict(image)\n",
    "predict_label = tf.argmax(result, axis=1)\n",
    "predict_label = predict_label.numpy()\n",
    "label_dict = {\"0\" : \"airplane\", \"1\": \"automobile\", \"2\": \"bird\", \"3\": \"cat\", \"4\": \"deer\",\n",
    "             \"5\": \"dog\", \"6\": \"frog\", \"7\": \"horse\", \"8\": \"ship\", \"9\": \"truck\"}\n",
    "for i in predict_label:\n",
    "    label = label_dict[str(i)]\n",
    "print(predict_label)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 调参优化模型，采用学习率衰减，检测学习率衰减"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False) #\n",
    "datagen.fit(x_train)\n",
    "## 训练模型\n",
    "if not os.path.exists(\"./models/vgg_lr/\"):\n",
    "    os.mkdir(\"./models/vgg_lr/\")\n",
    "ckpt = tf.io.gfile.listdir(\"./models/vgg_lr/\")\n",
    "if ckpt:\n",
    "    ## 加载训练好的模型\n",
    "    model_file = os.path.join(\"./models/vgg_lr/\", ckpt[-1]) ## 加载最新的模型文件\n",
    "    model = tf.keras.models.load_model(model_file)\n",
    "else:\n",
    "    model = VGGModel(0.3)\n",
    "    model = model.build_model()\n",
    "    model.summary()\n",
    "\n",
    "\n",
    "def lr_decay(epoch):\n",
    "    initial_lr = 0.01\n",
    "    drop = 0.5\n",
    "    epochs_drop = 20\n",
    "    lr = initial_lr * math.pow(drop, math.floor((1 + epoch)/epochs_drop))\n",
    "    return lr\n",
    "\n",
    "\n",
    "if not os.path.exists(\"/home/xiaofang/notebook/company_tf/CNN/logs_vgg/\"):\n",
    "    os.mkdir(\"/home/xiaofang/notebook/company_tf/CNN/logs_vgg/\")\n",
    "log_dir = \"/home/xiaofang/notebook/company_tf/CNN/logs_vgg/vgg_cifar10_event-{}\".format(int(time.time()))\n",
    "my_callbacks = [tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "               tf.keras.callbacks.LearningRateScheduler(lr_decay)]\n",
    "\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=64), \n",
    "                    steps_per_epoch=x_train.shape[0] // 64, epochs=200, validation_data=(x_test, y_test),\n",
    "                    callbacks=my_callbacks)\n",
    "checkpoint_path = os.path.join(\"./models/vgg_lr/\", \"vgg_cifar10.h5\")\n",
    "model.save(checkpoint_path)\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(x_test)\n",
    "pred_ = tf.equal(tf.argmax(result, 1), tf.argmax(y_test, 1))\n",
    "pred_ = tf.cast(pred_, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(pred_)\n",
    "print(\"测试准确率为： \", accuracy.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 卷积核kernel参数初始化\n",
    "   - glorot_normal\n",
    "   - glorot_uniform 是默认的方式\n",
    "   - he_normal\n",
    "   - he_uniform等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGGModel(object):\n",
    "    def __init__(self, drop_rate):\n",
    "        self.drop_rate = drop_rate\n",
    "    \n",
    "    def build_model(self):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(input_shape=(32, 32, 3), filters=64, kernel_size=(3, 3), \n",
    "                                         strides=(1, 1), padding=\"same\", activation=\"relu\", \n",
    "                                         kernel_initializer=\"glorot_normal\", name=\"conv1\"))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", kernel_initializer=\"glorot_normal\", name=\"conv2\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\", name=\"pool1\"))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", kernel_initializer=\"glorot_normal\", name=\"conv3\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", kernel_initializer=\"glorot_normal\", name=\"conv4\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\", name=\"pool2\"))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", kernel_initializer=\"glorot_normal\", name=\"conv5\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", kernel_initializer=\"glorot_normal\", name=\"conv6\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", kernel_initializer=\"glorot_normal\", name=\"conv7\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", kernel_initializer=\"glorot_normal\", name=\"conv8\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", kernel_initializer=\"glorot_normal\", name=\"conv9\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", kernel_initializer=\"glorot_normal\", name=\"conv10\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", kernel_initializer=\"glorot_normal\",name=\"conv11\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", kernel_initializer=\"glorot_normal\", name=\"conv12\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", kernel_initializer=\"glorot_normal\", name=\"conv13\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(512, activation=\"relu\", name=\"fc1\"))\n",
    "        model.add(tf.keras.layers.Dropout(self.drop_rate))\n",
    "        model.add(tf.keras.layers.Dense(256, activation=\"relu\", name=\"fc2\"))\n",
    "        model.add(tf.keras.layers.Dropout(self.drop_rate))\n",
    "        model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "        model.compile(optimizer=tf.keras.optimizers.SGD(0.01),\n",
    "                     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False) #\n",
    "datagen.fit(x_train)\n",
    "## 训练模型\n",
    "ckpt = tf.io.gfile.listdir(\"./models/vgg/\")\n",
    "if ckpt:\n",
    "    model_file = os.path.join(\"./models/vgg/\", ckpt[-1])\n",
    "    print(\"Reading model parameters from %s\" % model_file)\n",
    "    ## 加载模型\n",
    "    model = tf.keras.models.load_model(model_file)\n",
    "    model.summary()\n",
    "else:\n",
    "    vgg = VGGModel(0.3)\n",
    "    model = vgg.build_model()\n",
    "    model.summary()\n",
    "\n",
    "if not os.path.exists(\"./logs_vgg/\"):\n",
    "    os.mkdir(\"./logs_vgg/\")\n",
    "log_dir = \"./logs_vgg/vgg_cifar10_event-{}\".format(int(time.time()))\n",
    "my_callbacks = [tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)]\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=64), \n",
    "                    steps_per_epoch=x_train.shape[0] // 64, epochs=3, validation_data=(x_test, y_test),\n",
    "                    callbacks=my_callbacks)\n",
    "checkpoint_file = os.path.join(\"./models/vgg/vgg_cifar10.h5\")\n",
    "model.save(checkpoint_file)\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(x_test)\n",
    "pred_ = tf.equal(tf.argmax(result, 1), tf.argmax(y_test, 1))\n",
    "pred_ = tf.cast(pred_, dtype=tf.float32)\n",
    "accuracy = tf.reduce_mean(pred_)\n",
    "print(\"测试准确率为： \", accuracy.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu20",
   "language": "python",
   "name": "tensorflowgpu20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
