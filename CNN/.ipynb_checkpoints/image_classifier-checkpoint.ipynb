{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 搭建CNN模型，训练cifar100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cifar100数据集介绍"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cifar100数据集有20个大类别，每一个大类里面包含5个小类别。cifar100的数据有60000张图像，其中50000张是训练数据，10000张是测试数据，每一个类有500张训练数据和100张测试数据。\n",
    "<img src=\"./images/cifar100.png\" style=\"height: 60%;width: 60%; position: relative;right:10%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建CNN模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape:  (50000, 32, 32, 3)\n",
      "train label shape:  (50000, 1)\n",
      "test data shape:  (10000, 32, 32, 3)\n",
      "test label shape:  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "print(\"train data shape: \", x_train.shape)\n",
    "print(\"train label shape: \", y_train.shape)\n",
    "print(\"test data shape: \", x_test.shape)\n",
    "print(\"test label shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  121.93584\n",
      "std:  68.38902\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "means = np.mean(x_train, axis=(0, 1, 2, 3))\n",
    "stds = np.std(x_train, axis=(0, 1, 2, 3))\n",
    "print(\"mean: \", means)\n",
    "print(\"std: \", stds)\n",
    "x_train = (x_train - means) / (stds + 1e-5)\n",
    "x_test = (x_test - means) / (stds + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train, 100)\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 100)\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 搭建CNN模型\n",
    "  - 卷积\n",
    "  - batchNormalization\n",
    "  - 正则"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(object):\n",
    "    def __init__(self, drop_rate, learning_rate):\n",
    "        self.drop_rate = drop_rate\n",
    "        self.learning_rate = learning_rate\n",
    "        self.weights = 0.05\n",
    "        self.num_classes = 100\n",
    "    def build_model(self):\n",
    "        \n",
    "        model = tf.keras.Sequential()\n",
    "        model.add(tf.keras.layers.Conv2D(input_shape=(32, 32, 3), filters=64, kernel_size=(3, 3), \n",
    "                                         strides=(1, 1), padding=\"same\", activation=\"relu\", \n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(l=self.weights), \n",
    "                                         name=\"conv1\"))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
    "                                         activation=\"relu\", \n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(self.weights),\n",
    "                                         name=\"conv2\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\", name=\"pool1\"))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
    "                                         activation=\"relu\", \n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(self.weights),name=\"conv3\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", \n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(self.weights), name=\"conv4\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\", name=\"pool2\"))\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", \n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(self.weights), name=\"conv5\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", \n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(self.weights), name=\"conv6\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=256, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", \n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(self.weights), name=\"conv7\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.3))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", \n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(self.weights), name=\"conv8\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", \n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(self.weights), name=\"conv9\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", \n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(self.weights), name=\"conv10\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "\n",
    "\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", \n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(self.weights), name=\"conv11\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", \n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(self.weights), name=\"conv12\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.Conv2D(filters=512, kernel_size=(2, 2), strides=(1, 1), padding=\"same\",\n",
    "                                        activation=\"relu\", \n",
    "                                         kernel_regularizer=tf.keras.regularizers.l2(self.weights), name=\"conv13\"))\n",
    "        model.add(tf.keras.layers.BatchNormalization())\n",
    "        model.add(tf.keras.layers.Dropout(0.4))\n",
    "        model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\"))\n",
    "\n",
    "        model.add(tf.keras.layers.Flatten())\n",
    "        model.add(tf.keras.layers.Dense(512, activation=\"relu\", name=\"fc1\"))\n",
    "        model.add(tf.keras.layers.Dropout(self.drop_rate))\n",
    "        model.add(tf.keras.layers.Dense(256, activation=\"relu\", name=\"fc2\"))\n",
    "        model.add(tf.keras.layers.Dropout(self.drop_rate))\n",
    "        model.add(tf.keras.layers.Dense(self.num_classes, activation=\"softmax\"))\n",
    "        model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=self.learning_rate),\n",
    "                     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                     metrics=['accuracy'])\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练模型\n",
    " - 用ImageDataGenerator对数据进行反转，shift处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 16, 16, 128)       512       \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv5 (Conv2D)               (None, 8, 8, 256)         131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv6 (Conv2D)               (None, 8, 8, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv7 (Conv2D)               (None, 8, 8, 256)         262400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 8, 8, 256)         1024      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv8 (Conv2D)               (None, 4, 4, 512)         524800    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv9 (Conv2D)               (None, 4, 4, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv10 (Conv2D)              (None, 4, 4, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 4, 4, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv11 (Conv2D)              (None, 2, 2, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_23 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv12 (Conv2D)              (None, 2, 2, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv13 (Conv2D)              (None, 2, 2, 512)         1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 2, 2, 512)         2048      \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               25700     \n",
      "=================================================================\n",
      "Total params: 7,122,852\n",
      "Trainable params: 7,114,532\n",
      "Non-trainable params: 8,320\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From <ipython-input-7-718988f54462>:47: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 390 steps, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "390/390 [==============================] - 468s 1s/step - loss: 33.3045 - accuracy: 0.0142 - val_loss: 23.5970 - val_accuracy: 0.0111\n",
      "Epoch 2/2\n",
      "333/390 [========================>.....] - ETA: 1:07 - loss: 18.4949 - accuracy: 0.0156"
     ]
    }
   ],
   "source": [
    "imggen = tf.keras.preprocessing.image.ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False) #\n",
    "imggen.fit(x_train)\n",
    "## 参数\n",
    "batch_size = 128\n",
    "dropout = 0.3\n",
    "epochs = 2\n",
    "learning_rate = 0.01\n",
    "\n",
    "## 训练模型\n",
    "checkpoint_path = tf.io.gfile.listdir(\"./models/cnn_cifar100/\")\n",
    "if checkpoint_path:\n",
    "    ## 加载模型\n",
    "    model_file = os.path.join(\"./models/cnn_cifar100\", checkpoint_path[-1])\n",
    "    model = tf.keras.models.load_model(model_file)\n",
    "    model.summary()\n",
    "else:\n",
    "    model = CNNModel(dropout, learning_rate)\n",
    "    model = model.build_model()\n",
    "    model.summary()\n",
    "    \n",
    "def lr_decay(epoch):\n",
    "    initial_lr = 0.01\n",
    "    drop = 0.5\n",
    "    epochs_drop = 20\n",
    "    lr = initial_lr * math.pow(drop, math.floor((1 + epoch)/epochs_drop))\n",
    "    return lr\n",
    "\n",
    "## callbacks\n",
    "if not os.path.exists(\"./logs/\"):\n",
    "    os.mkdir(\"./logs/\")\n",
    "log_dir = \"./logs/cnn_cifar100_event-{}\".format(int(time.time()))\n",
    "my_callbacks = [tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "               tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3),\n",
    "               tf.keras.callbacks.LearningRateScheduler(lr_decay)]\n",
    "\n",
    "model.fit_generator(imggen.flow(x_train, y_train, batch_size=batch_size), \n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size, epochs=epochs, \n",
    "                    validation_data=(x_test, y_test), callbacks=my_callbacks)\n",
    "checkpoint = os.path.join(\"./models/cnn_cifar100/cnn_cifar100.h5\")\n",
    "model.save(checkpoint)\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.predict(x_test)\n",
    "acc = tf.equal(tf.argmax(result, axis=1), tf.argmax(y_test, axis=1))\n",
    "acc = tf.cast(acc, tf.float32)\n",
    "accuracy = tf.reduce_mean(acc)\n",
    "print(\"测试准确率为： \", accuracy.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu20",
   "language": "python",
   "name": "tensorflowgpu20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
