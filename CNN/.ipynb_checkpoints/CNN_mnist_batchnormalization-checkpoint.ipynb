{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BatchNormalization\n",
    "BatchNormalization是批归一化。在机器学习中，通常有一个独立同分布的假设，即训练集与测试集的分布是独立且相同的。这是通过训练数据获得的模型能够在测试集获得好的效果的一个基本保障。而BN就是在深度神经网络训练过程中使得每一层神经网络的输入保持相同分布的。\n",
    "- ### BatchNormalization直观理解：\n",
    "因为深层神经网络在做非线性变换前的激活输入值x随着网络深度加深或者在训练过程中，其分布逐渐发生偏移或者变动，之所以训练收敛慢，一般是整体分布逐渐往非线性函数的取值区间的上下限两端靠近，所以这导致反向传播时低层神经网络的梯度消失，这是训练深层神经网络收敛越来越慢的本质原因。\n",
    "而BN就是通过一定的规范化手段，把每层神经网络任意神经元这个输入值的分布强行拉回到均值为0方差为1的标准正态分布，其实就是把越来越偏的分布强制拉回比较标准的分布，这样使得激活输入值落在非线性函数对输入比较敏感的区域，这样输入的小变化就会导致损失函数较大的变化，意思是这样让梯度变大，避免梯度消失问题产生，而且梯度变大意味着学习收敛速度快，能大大加快训练速度。\n",
    "- ### BatchNormalization的原理\n",
    "<img src=\"./images/bn.png\" style=\"height: 60%;width: 60%; position: relative;right:10%\">\n",
    "- ### BatchNormalization的通俗理解\n",
    "输入的张量或者卷积后的张量(N,H,W,C),可以认为有N本书，每本书有C页，每一页有H行W列。BatchNormalization计算均值，将N本书一一按页码相加计算平均值，例如第一本书的第2页，第二本书的第2页，...,第N本书的第2页的所有字相加，除以N\\*H\\*W得到均值。方差也是类似的计算方法。BatchNormalization得到的是\"平均书\"(每一页书只有一个字)\n",
    "- ### BatchNormalization的优点\n",
    "  - 可以使用大的学习率\n",
    "  - 训练收敛速度加快\n",
    "- ### BatchNormalization的API介绍\n",
    "  - tf.keras.layers.BatchNormalization(\n",
    "    axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True,\n",
    "    beta_initializer='zeros', gamma_initializer='ones',\n",
    "    moving_mean_initializer='zeros', moving_variance_initializer='ones',\n",
    "    beta_regularizer=None, gamma_regularizer=None, beta_constraint=None,\n",
    "    gamma_constraint=None, renorm=False, renorm_clipping=None, renorm_momentum=0.99,\n",
    "    fused=None, trainable=True, virtual_batch_size=None, adjustment=None, name=None,\n",
    "    **kwargs)\n",
    "     - axis：整数，默认为-1，如果卷积后的数据格式data_format=\"channels_first\"，axis=1\n",
    "     - epsilon：避免分母为0\n",
    "     - trainable：默认为True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist training data shape:  (60000, 28, 28)\n",
      "mnist test data shape:  (10000, 28, 28)\n",
      "mnist training label shape:  (60000,)\n",
      "mnist test label shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(\"mnist training data shape: \", x_train.shape)\n",
    "print(\"mnist test data shape: \", x_test.shape)\n",
    "print(\"mnist training label shape: \", y_train.shape)\n",
    "print(\"mnist test label shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 可视化一张数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f853715ff60>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[10], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape:  (60000, 28, 28, 1)\n",
      "x_test shape:  (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape((-1, 28, 28, 1))\n",
    "x_test = x_test.reshape((-1, 28, 28, 1))\n",
    "print(\"x_train shape: \", x_train.shape)\n",
    "print(\"x_test shape: \", x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 构建模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv2D)               (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling2D)         (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 14, 14, 32)        9248      \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling2D)         (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                50208     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 78,986\n",
      "Trainable params: 78,794\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Conv2D(input_shape=(x_train.shape[1], x_train.shape[2], x_train.shape[3]),\n",
    "                                filters=32, kernel_size=(3, 3), strides=(1, 1),padding=\"same\", \n",
    "                                 activation=\"relu\", name=\"conv1\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1,1), padding=\"same\",\n",
    "                                activation=\"relu\", name=\"conv2\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2),strides=(2, 2), padding=\"valid\", name=\"pool1\"))\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", \n",
    "                                 activation=\"relu\",name=\"conv3\"))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), padding=\"same\",\n",
    "                                activation=\"relu\", name=\"conv4\"))\n",
    "model.add(tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\", name=\"pool2\"))\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(lr=0.01),\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/13\n",
      "54000/54000 [==============================] - 50s 931us/sample - loss: 0.2249 - accuracy: 0.9325 - val_loss: 0.0695 - val_accuracy: 0.9790\n",
      "Epoch 2/13\n",
      "54000/54000 [==============================] - 49s 905us/sample - loss: 0.0687 - accuracy: 0.9793 - val_loss: 0.0590 - val_accuracy: 0.9832\n",
      "Epoch 3/13\n",
      "54000/54000 [==============================] - 49s 903us/sample - loss: 0.0486 - accuracy: 0.9854 - val_loss: 0.0486 - val_accuracy: 0.9867\n",
      "Epoch 4/13\n",
      "54000/54000 [==============================] - 49s 915us/sample - loss: 0.0383 - accuracy: 0.9885 - val_loss: 0.0411 - val_accuracy: 0.9890\n",
      "Epoch 5/13\n",
      "54000/54000 [==============================] - 50s 921us/sample - loss: 0.0305 - accuracy: 0.9909 - val_loss: 0.0476 - val_accuracy: 0.9875\n",
      "Epoch 6/13\n",
      "54000/54000 [==============================] - 50s 918us/sample - loss: 0.0262 - accuracy: 0.9923 - val_loss: 0.0389 - val_accuracy: 0.9895\n",
      "Epoch 7/13\n",
      "54000/54000 [==============================] - 50s 921us/sample - loss: 0.0222 - accuracy: 0.9935 - val_loss: 0.0334 - val_accuracy: 0.9907\n",
      "Epoch 8/13\n",
      "54000/54000 [==============================] - 49s 914us/sample - loss: 0.0193 - accuracy: 0.9946 - val_loss: 0.0366 - val_accuracy: 0.9893\n",
      "Epoch 9/13\n",
      "54000/54000 [==============================] - 50s 917us/sample - loss: 0.0167 - accuracy: 0.9953 - val_loss: 0.0347 - val_accuracy: 0.9908\n",
      "Epoch 10/13\n",
      "54000/54000 [==============================] - 50s 927us/sample - loss: 0.0142 - accuracy: 0.9959 - val_loss: 0.0333 - val_accuracy: 0.9912\n",
      "Epoch 11/13\n",
      "54000/54000 [==============================] - 50s 921us/sample - loss: 0.0125 - accuracy: 0.9966 - val_loss: 0.0350 - val_accuracy: 0.9915\n",
      "Epoch 12/13\n",
      "54000/54000 [==============================] - 50s 933us/sample - loss: 0.0107 - accuracy: 0.9972 - val_loss: 0.0330 - val_accuracy: 0.9917\n",
      "Epoch 13/13\n",
      "54000/54000 [==============================] - 48s 880us/sample - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.0315 - val_accuracy: 0.9920\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "model_path = \"/home/xiaofang/notebook/company_tf/CNN/logs_bn/cnn_batch_event-{}\".format(int(time.time()))\n",
    "my_callback = [tf.keras.callbacks.ModelCheckpoint(\"./models/mnist_cnn/cnn_bn.h5\"),\n",
    "              tf.keras.callbacks.TensorBoard(log_dir=model_path, histogram_freq=1)]\n",
    "history = model.fit(x_train, y_train, batch_size=64, epochs=13, validation_split=0.1, callbacks=my_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 150us/sample - loss: 0.0346 - accuracy: 0.9891\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu20",
   "language": "python",
   "name": "tensorflowgpu20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
