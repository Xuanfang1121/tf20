{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGraph\n",
    "TensorFlow 2.0将TensorFlow1.0的强大功能与Eager Execution模式结合起来，同时合并的核心是tf.function，它允许将Python语法的子集转换为可移植的高性能TensorFlow图。tf.function的一个很酷的新功能是AutoGraph，可以使用自然的Python语法编写图形代码。\n",
    "- tf.function装饰器的作用\n",
    "  - 一个函数如何被tf.function注释，会被编译成图，但是依然可以按照函数调用\n",
    "  - 如果在注释的函数中，有被调用的函数，那么被调用的函数也将以图的模式运行。\n",
    "  - 支持python中的所有控制语句"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 1. tf.function装饰器\n",
    "当使用tf.function注释函数时，可以像调用任何其他函数一样调用它。它将被编译成图，这意味着可以获得更快执行，更好地在GPU或TPU上运行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def simple_nn_layer(x, y):\n",
    "    return tf.nn.relu(tf.matmul(x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=21, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0.        , 0.56820613, 0.29746196],\n",
       "       [0.        , 1.606781  , 3.155431  ],\n",
       "       [0.        , 0.        , 0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.normal(shape=[3, 3])\n",
    "y = tf.random.normal(shape=[3, 3])\n",
    "simple_nn_layer(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.def_function.Function at 0x1685a8f8940>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_nn_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 注意用tf.function修饰后的simple_nn_layer函数与直接定义的simple_nn_layer的区别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 不用tf.function修饰函数simple_nn_layer\n",
    "def simple_nn_layer(x, y):\n",
    "    return tf.nn.relu(tf.matmul(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=23, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0.        , 0.56820613, 0.29746196],\n",
       "       [0.        , 1.606781  , 3.155431  ],\n",
       "       [0.        , 0.        , 0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_nn_layer(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.simple_nn_layer(x, y)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_nn_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### 修饰的函数调用其他函数，这些函数也以图的模式运行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=42, shape=(3,), dtype=float32, numpy=array([3., 5., 7.], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def linear_layer(x):\n",
    "    return 2 * x + 1.0\n",
    "\n",
    "@tf.function\n",
    "def deep_net(x):\n",
    "    return tf.nn.relu(linear_layer(x))\n",
    "\n",
    "deep_net(tf.constant((1, 2.0, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- #### 支持python中的所有控制语句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(22, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def sum_even(x):\n",
    "    s = 0\n",
    "    for iterm in x:\n",
    "        if iterm % 2 != 0:\n",
    "            continue\n",
    "        s += iterm\n",
    "    return s\n",
    "\n",
    "result = sum_even(tf.constant([4, 7, 18, 15, 23]))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fizz\n",
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n",
      "Fizz\n",
      "16\n",
      "17\n",
      "Fizz\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "@tf.function\n",
    "def fizzbuzz(n):\n",
    "    for i in tf.range(n):\n",
    "        if i % 3 == 0:\n",
    "            tf.print('Fizz')\n",
    "        elif i % 5 == 0:\n",
    "            tf.print('Buzz')\n",
    "        else:\n",
    "            tf.print(i)\n",
    "\n",
    "fizzbuzz(tf.constant(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2.  Keras与AutoGraph\n",
    " - 可以通过注释模型的调用函数来装饰自定义Keras模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.  1. -3.]\n",
      " [ 1. -4.  2.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "class CustomModel(tf.keras.models.Model):\n",
    "    @tf.function\n",
    "    def call(self, inputs):\n",
    "        if tf.reduce_mean(inputs) > 0:\n",
    "            return inputs\n",
    "        else:\n",
    "            return inputs // 2\n",
    "        \n",
    "model = CustomModel()\n",
    "result = model(tf.constant([[1.0, 3.0, -5.0], [2.0, -7.5, 4]]))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  训练函数\n",
    "采用多层感知机对mnist数据集进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def prepare_mnist_features_and_labels(x, y):\n",
    "    x = tf.cast(x, tf.float32) / 255.0\n",
    "    y = tf.cast(y, tf.int64)\n",
    "    return x,y\n",
    "\n",
    "## 加载数据--方式1：缺点是一次性读入所有的数据，消耗的内存较大\n",
    "def read_mnist():\n",
    "    (x, y), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    print(\"mnist train data shape: \", x.shape)\n",
    "    print(\"mnist test data shape: \", x_test.shape)\n",
    "    print(\"mnist train data label: \", y[:30])\n",
    "    ###得到迭代的数据,遍历整个数据集\n",
    "    data = tf.data.Dataset.from_tensor_slices((x, y)) # 对输入的tensor以第一个维度切分数据，例如tensor的shape(200,28,28,3),切分200个shape为(28,28,3)的tensor\n",
    "    data = data.map(prepare_mnist_features_and_labels)\n",
    "    ### 筛选一部分数据作为训练集\n",
    "    # data = data.take(20000).shuffle(20000).batch(100)\n",
    "    data = data.shuffle(60000).batch(100)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 定义多层感知机模型\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(200, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "model.build()\n",
    "## 定义优化器\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "### 定义loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "### 定义准确率\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "### 定义梯度优化\n",
    "def one_step_gradient(model, optimizer, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        lossing = loss(y, logits)\n",
    "    ## 梯度\n",
    "    grads = tape.gradient(lossing, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    ## predict\n",
    "    predict = tf.nn.softmax(logits) ### 这个softmax到底需要不需要\n",
    "    accuracy(y, predict)\n",
    "    return lossing\n",
    "### 修饰训练函数\n",
    "@tf.function\n",
    "def training(model, optimizer):\n",
    "    ## 加载数据集\n",
    "    train_data = read_mnist()\n",
    "    epoches = 10\n",
    "    training_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "    for epoch in range(epoches):\n",
    "        step = 0\n",
    "        for batch_x, batch_y in train_data:\n",
    "            step += 1\n",
    "            training_loss = one_step_gradient(model, optimizer, batch_x, batch_y)\n",
    "            if step % 100 == 0:\n",
    "                tf.print(\"epoch: \", epoch + 1, \"step: \", step, \"training loss: \", training_loss, \n",
    "                         \"training accuracy: \", accuracy.result())\n",
    "    return step, training_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist train data shape:  (60000, 28, 28)\n",
      "mnist test data shape:  (10000, 28, 28)\n",
      "mnist train data label:  [5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7]\n",
      "mnist train data shape:  (60000, 28, 28)\n",
      "mnist test data shape:  (10000, 28, 28)\n",
      "mnist train data label:  [5 0 4 1 9 2 1 3 1 4 3 5 3 6 1 7 2 8 6 9 4 0 9 1 1 2 4 3 2 7]\n",
      "epoch:  1 step:  10 training loss:  1.63552809 training accuracy:  0.452\n",
      "epoch:  1 step:  20 training loss:  0.769016325 training accuracy:  0.5855\n",
      "epoch:  1 step:  30 training loss:  0.452850223 training accuracy:  0.664666653\n",
      "epoch:  1 step:  40 training loss:  0.367639244 training accuracy:  0.70975\n",
      "epoch:  1 step:  50 training loss:  0.565599203 training accuracy:  0.743\n",
      "epoch:  1 step:  60 training loss:  0.382287413 training accuracy:  0.767166674\n",
      "epoch:  1 step:  70 training loss:  0.412267685 training accuracy:  0.785428584\n",
      "epoch:  1 step:  80 training loss:  0.424208283 training accuracy:  0.80025\n",
      "epoch:  1 step:  90 training loss:  0.421686709 training accuracy:  0.810333312\n",
      "epoch:  1 step:  100 training loss:  0.294938385 training accuracy:  0.821\n",
      "epoch:  1 step:  110 training loss:  0.355232894 training accuracy:  0.829727292\n",
      "epoch:  1 step:  120 training loss:  0.213588789 training accuracy:  0.838083327\n",
      "epoch:  1 step:  130 training loss:  0.328585744 training accuracy:  0.844846129\n",
      "epoch:  1 step:  140 training loss:  0.264939874 training accuracy:  0.849928558\n",
      "epoch:  1 step:  150 training loss:  0.279223919 training accuracy:  0.8546\n",
      "epoch:  1 step:  160 training loss:  0.365994602 training accuracy:  0.859062493\n",
      "epoch:  1 step:  170 training loss:  0.214090571 training accuracy:  0.863\n",
      "epoch:  1 step:  180 training loss:  0.318909466 training accuracy:  0.866833329\n",
      "epoch:  1 step:  190 training loss:  0.395923644 training accuracy:  0.869315803\n",
      "epoch:  1 step:  200 training loss:  0.237969115 training accuracy:  0.87315\n",
      "epoch:  1 step:  210 training loss:  0.277457476 training accuracy:  0.876238108\n",
      "epoch:  1 step:  220 training loss:  0.199756145 training accuracy:  0.879318178\n",
      "epoch:  1 step:  230 training loss:  0.215774179 training accuracy:  0.882\n",
      "epoch:  1 step:  240 training loss:  0.121835798 training accuracy:  0.884458363\n",
      "epoch:  1 step:  250 training loss:  0.233750969 training accuracy:  0.88636\n",
      "epoch:  1 step:  260 training loss:  0.218531743 training accuracy:  0.887961566\n",
      "epoch:  1 step:  270 training loss:  0.239502892 training accuracy:  0.889629602\n",
      "epoch:  1 step:  280 training loss:  0.160592958 training accuracy:  0.891285717\n",
      "epoch:  1 step:  290 training loss:  0.210937932 training accuracy:  0.893172443\n",
      "epoch:  1 step:  300 training loss:  0.157813072 training accuracy:  0.8946\n",
      "epoch:  1 step:  310 training loss:  0.199421629 training accuracy:  0.895935476\n",
      "epoch:  1 step:  320 training loss:  0.150507435 training accuracy:  0.897875\n",
      "epoch:  1 step:  330 training loss:  0.259606391 training accuracy:  0.899424255\n",
      "epoch:  1 step:  340 training loss:  0.129033148 training accuracy:  0.900647044\n",
      "epoch:  1 step:  350 training loss:  0.173346 training accuracy:  0.902\n",
      "epoch:  1 step:  360 training loss:  0.122949183 training accuracy:  0.903194427\n",
      "epoch:  1 step:  370 training loss:  0.187616408 training accuracy:  0.904\n",
      "epoch:  1 step:  380 training loss:  0.172330767 training accuracy:  0.905052602\n",
      "epoch:  1 step:  390 training loss:  0.156428874 training accuracy:  0.906102538\n",
      "epoch:  1 step:  400 training loss:  0.122727625 training accuracy:  0.907125\n",
      "epoch:  1 step:  410 training loss:  0.128150836 training accuracy:  0.90790242\n",
      "epoch:  1 step:  420 training loss:  0.204494044 training accuracy:  0.90866667\n",
      "epoch:  1 step:  430 training loss:  0.0926235393 training accuracy:  0.909581423\n",
      "epoch:  1 step:  440 training loss:  0.191204891 training accuracy:  0.910590887\n",
      "epoch:  1 step:  450 training loss:  0.186328948 training accuracy:  0.911711097\n",
      "epoch:  1 step:  460 training loss:  0.122470714 training accuracy:  0.912826061\n",
      "epoch:  1 step:  470 training loss:  0.149660707 training accuracy:  0.913553178\n",
      "epoch:  1 step:  480 training loss:  0.112000838 training accuracy:  0.914437473\n",
      "epoch:  1 step:  490 training loss:  0.176392421 training accuracy:  0.915020406\n",
      "epoch:  1 step:  500 training loss:  0.202595711 training accuracy:  0.91576\n",
      "epoch:  1 step:  510 training loss:  0.123441145 training accuracy:  0.916392148\n",
      "epoch:  1 step:  520 training loss:  0.228600577 training accuracy:  0.917403817\n",
      "epoch:  1 step:  530 training loss:  0.0654139891 training accuracy:  0.918132067\n",
      "epoch:  1 step:  540 training loss:  0.0575389229 training accuracy:  0.918833315\n",
      "epoch:  1 step:  550 training loss:  0.125722975 training accuracy:  0.919363618\n",
      "epoch:  1 step:  560 training loss:  0.284900635 training accuracy:  0.920089304\n",
      "epoch:  1 step:  570 training loss:  0.138928398 training accuracy:  0.920561433\n",
      "epoch:  1 step:  580 training loss:  0.185424805 training accuracy:  0.921120703\n",
      "epoch:  1 step:  590 training loss:  0.161236987 training accuracy:  0.921830535\n",
      "epoch:  1 step:  600 training loss:  0.148027331 training accuracy:  0.922516644\n",
      "epoch:  2 step:  10 training loss:  0.0701448 training accuracy:  0.923262298\n",
      "epoch:  2 step:  20 training loss:  0.0761983171 training accuracy:  0.92408067\n",
      "epoch:  2 step:  30 training loss:  0.176331252 training accuracy:  0.924698412\n",
      "epoch:  2 step:  40 training loss:  0.0577716678 training accuracy:  0.925406277\n",
      "epoch:  2 step:  50 training loss:  0.128678873 training accuracy:  0.925861537\n",
      "epoch:  2 step:  60 training loss:  0.136946946 training accuracy:  0.926560581\n",
      "epoch:  2 step:  70 training loss:  0.10580679 training accuracy:  0.927149236\n",
      "epoch:  2 step:  80 training loss:  0.0635589659 training accuracy:  0.927779436\n",
      "epoch:  2 step:  90 training loss:  0.170578942 training accuracy:  0.928391278\n",
      "epoch:  2 step:  100 training loss:  0.137210965 training accuracy:  0.929\n",
      "epoch:  2 step:  110 training loss:  0.0615315624 training accuracy:  0.929521143\n",
      "epoch:  2 step:  120 training loss:  0.11726588 training accuracy:  0.929958344\n",
      "epoch:  2 step:  130 training loss:  0.101184882 training accuracy:  0.930479467\n",
      "epoch:  2 step:  140 training loss:  0.130419314 training accuracy:  0.930959463\n",
      "epoch:  2 step:  150 training loss:  0.0726207942 training accuracy:  0.931466639\n",
      "epoch:  2 step:  160 training loss:  0.219725281 training accuracy:  0.931868434\n",
      "epoch:  2 step:  170 training loss:  0.0654191524 training accuracy:  0.932272732\n",
      "epoch:  2 step:  180 training loss:  0.0703760087 training accuracy:  0.932602584\n",
      "epoch:  2 step:  190 training loss:  0.0461000577 training accuracy:  0.933\n",
      "epoch:  2 step:  200 training loss:  0.0694523081 training accuracy:  0.9335\n",
      "epoch:  2 step:  210 training loss:  0.114253826 training accuracy:  0.933814824\n",
      "epoch:  2 step:  220 training loss:  0.0718419626 training accuracy:  0.934280515\n",
      "epoch:  2 step:  230 training loss:  0.183025 training accuracy:  0.9347229\n",
      "epoch:  2 step:  240 training loss:  0.121486485 training accuracy:  0.935130954\n",
      "epoch:  2 step:  250 training loss:  0.0783445835 training accuracy:  0.935635269\n",
      "epoch:  2 step:  260 training loss:  0.106628925 training accuracy:  0.936011612\n",
      "epoch:  2 step:  270 training loss:  0.0682672262 training accuracy:  0.936482787\n",
      "epoch:  2 step:  280 training loss:  0.0954223573 training accuracy:  0.936897755\n",
      "epoch:  2 step:  290 training loss:  0.0749293119 training accuracy:  0.937179804\n",
      "epoch:  2 step:  300 training loss:  0.141623691 training accuracy:  0.937522233\n",
      "epoch:  2 step:  310 training loss:  0.0483329184 training accuracy:  0.93790108\n",
      "epoch:  2 step:  320 training loss:  0.159135103 training accuracy:  0.938206494\n",
      "epoch:  2 step:  330 training loss:  0.263687223 training accuracy:  0.93851614\n",
      "epoch:  2 step:  340 training loss:  0.0458345935 training accuracy:  0.938904226\n",
      "epoch:  2 step:  350 training loss:  0.0663041174 training accuracy:  0.9392\n",
      "epoch:  2 step:  360 training loss:  0.128609553 training accuracy:  0.939437509\n",
      "epoch:  2 step:  370 training loss:  0.0526106693 training accuracy:  0.93976289\n",
      "epoch:  2 step:  380 training loss:  0.137517437 training accuracy:  0.939969361\n",
      "epoch:  2 step:  390 training loss:  0.101055831 training accuracy:  0.940181792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  2 step:  400 training loss:  0.0582469888 training accuracy:  0.94059\n",
      "epoch:  2 step:  410 training loss:  0.0396924764 training accuracy:  0.940891087\n",
      "epoch:  2 step:  420 training loss:  0.0955961645 training accuracy:  0.941264689\n",
      "epoch:  2 step:  430 training loss:  0.0255029611 training accuracy:  0.941514552\n",
      "epoch:  2 step:  440 training loss:  0.0563107878 training accuracy:  0.941894233\n",
      "epoch:  2 step:  450 training loss:  0.104376018 training accuracy:  0.942133307\n",
      "epoch:  2 step:  460 training loss:  0.040781159 training accuracy:  0.942415118\n",
      "epoch:  2 step:  470 training loss:  0.0387414731 training accuracy:  0.942719638\n",
      "epoch:  2 step:  480 training loss:  0.157482266 training accuracy:  0.94299072\n",
      "epoch:  2 step:  490 training loss:  0.103141077 training accuracy:  0.943211\n",
      "epoch:  2 step:  500 training loss:  0.198927 training accuracy:  0.943445444\n",
      "epoch:  2 step:  510 training loss:  0.153759256 training accuracy:  0.943720698\n",
      "epoch:  2 step:  520 training loss:  0.116373807 training accuracy:  0.944017828\n",
      "epoch:  2 step:  530 training loss:  0.0442612655 training accuracy:  0.944274366\n",
      "epoch:  2 step:  540 training loss:  0.167687565 training accuracy:  0.944429815\n",
      "epoch:  2 step:  550 training loss:  0.169657931 training accuracy:  0.9446522\n",
      "epoch:  2 step:  560 training loss:  0.0740067288 training accuracy:  0.94493103\n",
      "epoch:  2 step:  570 training loss:  0.0762629956 training accuracy:  0.945179462\n",
      "epoch:  2 step:  580 training loss:  0.10455963 training accuracy:  0.945347428\n",
      "epoch:  2 step:  590 training loss:  0.0437186 training accuracy:  0.94560504\n",
      "epoch:  2 step:  600 training loss:  0.100220673 training accuracy:  0.945808351\n",
      "epoch:  3 step:  10 training loss:  0.0937592685 training accuracy:  0.946115732\n",
      "epoch:  3 step:  20 training loss:  0.0222155545 training accuracy:  0.946467221\n",
      "epoch:  3 step:  30 training loss:  0.0377795063 training accuracy:  0.946747959\n",
      "epoch:  3 step:  40 training loss:  0.114022657 training accuracy:  0.94699192\n",
      "epoch:  3 step:  50 training loss:  0.105960704 training accuracy:  0.947296\n",
      "epoch:  3 step:  60 training loss:  0.157113031 training accuracy:  0.947571456\n",
      "epoch:  3 step:  70 training loss:  0.133877426 training accuracy:  0.947811\n",
      "epoch:  3 step:  80 training loss:  0.100275889 training accuracy:  0.948054671\n",
      "epoch:  3 step:  90 training loss:  0.104463875 training accuracy:  0.948232532\n",
      "epoch:  3 step:  100 training loss:  0.0204713158 training accuracy:  0.948546171\n",
      "epoch:  3 step:  110 training loss:  0.0323170274 training accuracy:  0.948778629\n",
      "epoch:  3 step:  120 training loss:  0.0700714737 training accuracy:  0.949015141\n",
      "epoch:  3 step:  130 training loss:  0.0816013366 training accuracy:  0.949218035\n",
      "epoch:  3 step:  140 training loss:  0.0351667888 training accuracy:  0.949477613\n",
      "epoch:  3 step:  150 training loss:  0.0594873615 training accuracy:  0.949696302\n",
      "epoch:  3 step:  160 training loss:  0.144580528 training accuracy:  0.949867666\n",
      "epoch:  3 step:  170 training loss:  0.148202643 training accuracy:  0.950058401\n",
      "epoch:  3 step:  180 training loss:  0.141219705 training accuracy:  0.950289845\n",
      "epoch:  3 step:  190 training loss:  0.111588173 training accuracy:  0.9505108\n",
      "epoch:  3 step:  200 training loss:  0.0142362257 training accuracy:  0.95071429\n",
      "epoch:  3 step:  210 training loss:  0.0700625256 training accuracy:  0.950957417\n",
      "epoch:  3 step:  220 training loss:  0.06739977 training accuracy:  0.951218307\n",
      "epoch:  3 step:  230 training loss:  0.10160473 training accuracy:  0.951398611\n",
      "epoch:  3 step:  240 training loss:  0.0759204701 training accuracy:  0.951562524\n",
      "epoch:  3 step:  250 training loss:  0.0710339546 training accuracy:  0.951765537\n",
      "epoch:  3 step:  260 training loss:  0.0960404 training accuracy:  0.951938331\n",
      "epoch:  3 step:  270 training loss:  0.0178093147 training accuracy:  0.952054441\n",
      "epoch:  3 step:  280 training loss:  0.0476878509 training accuracy:  0.952162147\n",
      "epoch:  3 step:  290 training loss:  0.0503882132 training accuracy:  0.952328861\n",
      "epoch:  3 step:  300 training loss:  0.138175383 training accuracy:  0.952513337\n",
      "epoch:  3 step:  310 training loss:  0.0378068164 training accuracy:  0.952688754\n",
      "epoch:  3 step:  320 training loss:  0.0389752425 training accuracy:  0.952894747\n",
      "epoch:  3 step:  330 training loss:  0.0981310084 training accuracy:  0.953052282\n",
      "epoch:  3 step:  340 training loss:  0.050042633 training accuracy:  0.9531883\n",
      "epoch:  3 step:  350 training loss:  0.0755702779 training accuracy:  0.953361273\n",
      "epoch:  3 step:  360 training loss:  0.0529579222 training accuracy:  0.953551292\n",
      "epoch:  3 step:  370 training loss:  0.0993035436 training accuracy:  0.953707\n",
      "epoch:  3 step:  380 training loss:  0.0655683056 training accuracy:  0.953898728\n",
      "epoch:  3 step:  390 training loss:  0.0760885 training accuracy:  0.954012573\n",
      "epoch:  3 step:  400 training loss:  0.0443385728 training accuracy:  0.95415628\n",
      "epoch:  3 step:  410 training loss:  0.0221395753 training accuracy:  0.954298139\n",
      "epoch:  3 step:  420 training loss:  0.0957550704 training accuracy:  0.954425931\n",
      "epoch:  3 step:  430 training loss:  0.242168695 training accuracy:  0.954533756\n",
      "epoch:  3 step:  440 training loss:  0.0528008938 training accuracy:  0.954695106\n",
      "epoch:  3 step:  450 training loss:  0.052342616 training accuracy:  0.954836369\n",
      "epoch:  3 step:  460 training loss:  0.0190159064 training accuracy:  0.954969883\n",
      "epoch:  3 step:  470 training loss:  0.146658406 training accuracy:  0.955119789\n",
      "epoch:  3 step:  480 training loss:  0.120945968 training accuracy:  0.95525\n",
      "epoch:  3 step:  490 training loss:  0.101945408 training accuracy:  0.95537281\n",
      "epoch:  3 step:  500 training loss:  0.0614990443 training accuracy:  0.955505908\n",
      "epoch:  3 step:  510 training loss:  0.102797836 training accuracy:  0.955643296\n",
      "epoch:  3 step:  520 training loss:  0.0770885721 training accuracy:  0.955767453\n",
      "epoch:  3 step:  530 training loss:  0.050119739 training accuracy:  0.955907524\n",
      "epoch:  3 step:  540 training loss:  0.078456156 training accuracy:  0.956023\n",
      "epoch:  3 step:  550 training loss:  0.0729433373 training accuracy:  0.956182837\n",
      "epoch:  3 step:  560 training loss:  0.0376247354 training accuracy:  0.956272721\n",
      "epoch:  3 step:  570 training loss:  0.0531717315 training accuracy:  0.956333339\n",
      "epoch:  3 step:  580 training loss:  0.0699998438 training accuracy:  0.956466317\n",
      "epoch:  3 step:  590 training loss:  0.0712079555 training accuracy:  0.9566257\n",
      "epoch:  3 step:  600 training loss:  0.113031395 training accuracy:  0.95670557\n",
      "epoch:  4 step:  10 training loss:  0.0108251115 training accuracy:  0.956867397\n",
      "epoch:  4 step:  20 training loss:  0.0315815732 training accuracy:  0.957\n",
      "epoch:  4 step:  30 training loss:  0.0618130192 training accuracy:  0.957147539\n",
      "epoch:  4 step:  40 training loss:  0.129547313 training accuracy:  0.957293451\n",
      "epoch:  4 step:  50 training loss:  0.0651638 training accuracy:  0.957427\n",
      "epoch:  4 step:  60 training loss:  0.0484806821 training accuracy:  0.957569897\n",
      "epoch:  4 step:  70 training loss:  0.0212391727 training accuracy:  0.957716584\n",
      "epoch:  4 step:  80 training loss:  0.0523146093 training accuracy:  0.957851052\n",
      "epoch:  4 step:  90 training loss:  0.0251138639 training accuracy:  0.957994699\n",
      "epoch:  4 step:  100 training loss:  0.0658559576 training accuracy:  0.958147347\n",
      "epoch:  4 step:  110 training loss:  0.0154614197 training accuracy:  0.958308876\n",
      "epoch:  4 step:  120 training loss:  0.040124841 training accuracy:  0.958437502\n",
      "epoch:  4 step:  130 training loss:  0.0095780082 training accuracy:  0.958595872\n",
      "epoch:  4 step:  140 training loss:  0.0450169668 training accuracy:  0.958742261\n",
      "epoch:  4 step:  150 training loss:  0.123278618 training accuracy:  0.958871782\n",
      "epoch:  4 step:  160 training loss:  0.0311134141 training accuracy:  0.95901531\n",
      "epoch:  4 step:  170 training loss:  0.0277705137 training accuracy:  0.959177673\n",
      "epoch:  4 step:  180 training loss:  0.0725584254 training accuracy:  0.959318161\n",
      "epoch:  4 step:  190 training loss:  0.0462132022 training accuracy:  0.959432185\n",
      "epoch:  4 step:  200 training loss:  0.0238188338 training accuracy:  0.959555\n",
      "epoch:  4 step:  210 training loss:  0.0530496947 training accuracy:  0.959706485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  4 step:  220 training loss:  0.0633514524 training accuracy:  0.959792078\n",
      "epoch:  4 step:  230 training loss:  0.0257479195 training accuracy:  0.959896564\n",
      "epoch:  4 step:  240 training loss:  0.0114299925 training accuracy:  0.960049033\n",
      "epoch:  4 step:  250 training loss:  0.0468564704 training accuracy:  0.960161\n",
      "epoch:  4 step:  260 training loss:  0.0104713961 training accuracy:  0.960296094\n",
      "epoch:  4 step:  270 training loss:  0.0616436526 training accuracy:  0.960405827\n",
      "epoch:  4 step:  280 training loss:  0.0112006404 training accuracy:  0.960485578\n",
      "epoch:  4 step:  290 training loss:  0.0444429927 training accuracy:  0.960626781\n",
      "epoch:  4 step:  300 training loss:  0.0933836922 training accuracy:  0.960728586\n",
      "epoch:  4 step:  310 training loss:  0.0266094953 training accuracy:  0.960843623\n",
      "epoch:  4 step:  320 training loss:  0.0500821732 training accuracy:  0.960924506\n",
      "epoch:  4 step:  330 training loss:  0.00926425308 training accuracy:  0.961009383\n",
      "epoch:  4 step:  340 training loss:  0.0124425944 training accuracy:  0.961158872\n",
      "epoch:  4 step:  350 training loss:  0.0232780427 training accuracy:  0.961297691\n",
      "epoch:  4 step:  360 training loss:  0.0250041224 training accuracy:  0.961398125\n",
      "epoch:  4 step:  370 training loss:  0.0305308271 training accuracy:  0.961493075\n",
      "epoch:  4 step:  380 training loss:  0.0700696856 training accuracy:  0.961564243\n",
      "epoch:  4 step:  390 training loss:  0.0666051358 training accuracy:  0.961648405\n",
      "epoch:  4 step:  400 training loss:  0.0354006253 training accuracy:  0.961745441\n",
      "epoch:  4 step:  410 training loss:  0.0703152 training accuracy:  0.961778283\n",
      "epoch:  4 step:  420 training loss:  0.0327084288 training accuracy:  0.961855829\n",
      "epoch:  4 step:  430 training loss:  0.0356763266 training accuracy:  0.961937249\n",
      "epoch:  4 step:  440 training loss:  0.139306694 training accuracy:  0.962017834\n",
      "epoch:  4 step:  450 training loss:  0.0335460603 training accuracy:  0.962084472\n",
      "epoch:  4 step:  460 training loss:  0.061243955 training accuracy:  0.962172568\n",
      "epoch:  4 step:  470 training loss:  0.0479638353 training accuracy:  0.962255478\n",
      "epoch:  4 step:  480 training loss:  0.0123103429 training accuracy:  0.962346494\n",
      "epoch:  4 step:  490 training loss:  0.0842979252 training accuracy:  0.962432325\n",
      "epoch:  4 step:  500 training loss:  0.0214130823 training accuracy:  0.962547839\n",
      "epoch:  4 step:  510 training loss:  0.0620872974 training accuracy:  0.962584436\n",
      "epoch:  4 step:  520 training loss:  0.0789022 training accuracy:  0.962698281\n",
      "epoch:  4 step:  530 training loss:  0.0735582858 training accuracy:  0.962781131\n",
      "epoch:  4 step:  540 training loss:  0.0281862635 training accuracy:  0.962901711\n",
      "epoch:  4 step:  550 training loss:  0.0573896058 training accuracy:  0.962978721\n",
      "epoch:  4 step:  560 training loss:  0.0740740374 training accuracy:  0.963072062\n",
      "epoch:  4 step:  570 training loss:  0.0159323104 training accuracy:  0.9631688\n",
      "epoch:  4 step:  580 training loss:  0.0116271712 training accuracy:  0.963231087\n",
      "epoch:  4 step:  590 training loss:  0.0777818486 training accuracy:  0.963318\n",
      "epoch:  4 step:  600 training loss:  0.037856292 training accuracy:  0.963391662\n",
      "epoch:  5 step:  10 training loss:  0.0206248742 training accuracy:  0.963493764\n",
      "epoch:  5 step:  20 training loss:  0.0235829018 training accuracy:  0.963595033\n",
      "epoch:  5 step:  30 training loss:  0.0399095565 training accuracy:  0.963699579\n",
      "epoch:  5 step:  40 training loss:  0.0110131372 training accuracy:  0.963831961\n",
      "epoch:  5 step:  50 training loss:  0.0464842469 training accuracy:  0.963922441\n",
      "epoch:  5 step:  60 training loss:  0.0392498448 training accuracy:  0.964036584\n",
      "epoch:  5 step:  70 training loss:  0.0302266646 training accuracy:  0.964149773\n",
      "epoch:  5 step:  80 training loss:  0.0284178164 training accuracy:  0.964262068\n",
      "epoch:  5 step:  90 training loss:  0.0203146189 training accuracy:  0.964337349\n",
      "epoch:  5 step:  100 training loss:  0.00914815068 training accuracy:  0.964448\n",
      "epoch:  5 step:  110 training loss:  0.163785338 training accuracy:  0.964537859\n",
      "epoch:  5 step:  120 training loss:  0.0321183577 training accuracy:  0.964654744\n",
      "epoch:  5 step:  130 training loss:  0.0241897088 training accuracy:  0.96473515\n",
      "epoch:  5 step:  140 training loss:  0.0748723745 training accuracy:  0.964838564\n",
      "epoch:  5 step:  150 training loss:  0.0316606 training accuracy:  0.964933336\n",
      "epoch:  5 step:  160 training loss:  0.0907589421 training accuracy:  0.965035141\n",
      "epoch:  5 step:  170 training loss:  0.010840157 training accuracy:  0.965093374\n",
      "epoch:  5 step:  180 training loss:  0.0210439228 training accuracy:  0.965178311\n",
      "epoch:  5 step:  190 training loss:  0.0211729091 training accuracy:  0.96527797\n",
      "epoch:  5 step:  200 training loss:  0.0171445645 training accuracy:  0.96536541\n",
      "epoch:  5 step:  210 training loss:  0.0101368912 training accuracy:  0.965432942\n",
      "epoch:  5 step:  220 training loss:  0.0133299949 training accuracy:  0.9655267\n",
      "epoch:  5 step:  230 training loss:  0.0458454527 training accuracy:  0.965616\n",
      "epoch:  5 step:  240 training loss:  0.0513830371 training accuracy:  0.965715885\n",
      "epoch:  5 step:  250 training loss:  0.0882602483 training accuracy:  0.965788662\n",
      "epoch:  5 step:  260 training loss:  0.0405659787 training accuracy:  0.965860903\n",
      "epoch:  5 step:  270 training loss:  0.0139376475 training accuracy:  0.965947568\n",
      "epoch:  5 step:  280 training loss:  0.0592642464 training accuracy:  0.966026127\n",
      "epoch:  5 step:  290 training loss:  0.0289289858 training accuracy:  0.966107786\n",
      "epoch:  5 step:  300 training loss:  0.00337863318 training accuracy:  0.9662\n",
      "epoch:  5 step:  310 training loss:  0.0483827442 training accuracy:  0.966265678\n",
      "epoch:  5 step:  320 training loss:  0.0297999792 training accuracy:  0.96635294\n",
      "epoch:  5 step:  330 training loss:  0.0165688675 training accuracy:  0.966410279\n",
      "epoch:  5 step:  340 training loss:  0.00569799542 training accuracy:  0.966474473\n",
      "epoch:  5 step:  350 training loss:  0.0353082679 training accuracy:  0.966545463\n",
      "epoch:  5 step:  360 training loss:  0.0805219933 training accuracy:  0.966623187\n",
      "epoch:  5 step:  370 training loss:  0.0417951047 training accuracy:  0.966696739\n",
      "epoch:  5 step:  380 training loss:  0.0227278788 training accuracy:  0.966769755\n",
      "epoch:  5 step:  390 training loss:  0.0183316246 training accuracy:  0.966835141\n",
      "epoch:  5 step:  400 training loss:  0.0139415311 training accuracy:  0.966903567\n",
      "epoch:  5 step:  410 training loss:  0.0119341193 training accuracy:  0.966971517\n",
      "epoch:  5 step:  420 training loss:  0.0088451663 training accuracy:  0.967046082\n",
      "epoch:  5 step:  430 training loss:  0.00189137773 training accuracy:  0.967116594\n",
      "epoch:  5 step:  440 training loss:  0.124119766 training accuracy:  0.967169\n",
      "epoch:  5 step:  450 training loss:  0.00487879198 training accuracy:  0.967217565\n",
      "epoch:  5 step:  460 training loss:  0.0146440212 training accuracy:  0.967272699\n",
      "epoch:  5 step:  470 training loss:  0.053177204 training accuracy:  0.967327535\n",
      "epoch:  5 step:  480 training loss:  0.046196986 training accuracy:  0.967375\n",
      "epoch:  5 step:  490 training loss:  0.100304097 training accuracy:  0.967449844\n",
      "epoch:  5 step:  500 training loss:  0.0539956465 training accuracy:  0.967517257\n",
      "epoch:  5 step:  510 training loss:  0.0479060709 training accuracy:  0.967560112\n",
      "epoch:  5 step:  520 training loss:  0.0071077859 training accuracy:  0.967637\n",
      "epoch:  5 step:  530 training loss:  0.0230658893 training accuracy:  0.967703044\n",
      "epoch:  5 step:  540 training loss:  0.021274548 training accuracy:  0.967758477\n",
      "epoch:  5 step:  550 training loss:  0.00698724156 training accuracy:  0.967806756\n",
      "epoch:  5 step:  560 training loss:  0.0752375 training accuracy:  0.967881739\n",
      "epoch:  5 step:  570 training loss:  0.00771213043 training accuracy:  0.967915833\n",
      "epoch:  5 step:  580 training loss:  0.0825082287 training accuracy:  0.967969775\n",
      "epoch:  5 step:  590 training loss:  0.00602866337 training accuracy:  0.968016744\n",
      "epoch:  5 step:  600 training loss:  0.0721064582 training accuracy:  0.968063354\n",
      "epoch:  6 step:  10 training loss:  0.0154426126 training accuracy:  0.968132913\n",
      "epoch:  6 step:  20 training loss:  0.0130584128 training accuracy:  0.968218565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  6 step:  30 training loss:  0.0550001971 training accuracy:  0.968280554\n",
      "epoch:  6 step:  40 training loss:  0.0606565103 training accuracy:  0.968335509\n",
      "epoch:  6 step:  50 training loss:  0.025787726 training accuracy:  0.968406558\n",
      "epoch:  6 step:  60 training loss:  0.0134201869 training accuracy:  0.96847713\n",
      "epoch:  6 step:  70 training loss:  0.0187880546 training accuracy:  0.968547225\n",
      "epoch:  6 step:  80 training loss:  0.0190022159 training accuracy:  0.968613625\n",
      "epoch:  6 step:  90 training loss:  0.00367343449 training accuracy:  0.968692541\n",
      "epoch:  6 step:  100 training loss:  0.0126949428 training accuracy:  0.968771\n",
      "epoch:  6 step:  110 training loss:  0.0312536955 training accuracy:  0.968848884\n",
      "epoch:  6 step:  120 training loss:  0.00953768659 training accuracy:  0.968900621\n",
      "epoch:  6 step:  130 training loss:  0.0321978964 training accuracy:  0.96895206\n",
      "epoch:  6 step:  140 training loss:  0.0199158918 training accuracy:  0.969025493\n",
      "epoch:  6 step:  150 training loss:  0.00566303497 training accuracy:  0.969101608\n",
      "epoch:  6 step:  160 training loss:  0.00715216296 training accuracy:  0.969180405\n",
      "epoch:  6 step:  170 training loss:  0.0138159478 training accuracy:  0.969239771\n",
      "epoch:  6 step:  180 training loss:  0.00883112941 training accuracy:  0.969308197\n",
      "epoch:  6 step:  190 training loss:  0.0480262153 training accuracy:  0.969388723\n",
      "epoch:  6 step:  200 training loss:  0.0790405 training accuracy:  0.969459355\n",
      "epoch:  6 step:  210 training loss:  0.0316534638 training accuracy:  0.96952647\n",
      "epoch:  6 step:  220 training loss:  0.0216265917 training accuracy:  0.969586968\n",
      "epoch:  6 step:  230 training loss:  0.0224748272 training accuracy:  0.969653249\n",
      "epoch:  6 step:  240 training loss:  0.00707736192 training accuracy:  0.969725311\n",
      "epoch:  6 step:  250 training loss:  0.024917366 training accuracy:  0.969787717\n",
      "epoch:  6 step:  260 training loss:  0.0457244664 training accuracy:  0.969834328\n",
      "epoch:  6 step:  270 training loss:  0.0119057111 training accuracy:  0.969902158\n",
      "epoch:  6 step:  280 training loss:  0.0339780934 training accuracy:  0.969957292\n",
      "epoch:  6 step:  290 training loss:  0.102162145 training accuracy:  0.970006108\n",
      "epoch:  6 step:  300 training loss:  0.0349153541 training accuracy:  0.970057547\n",
      "epoch:  6 step:  310 training loss:  0.00623437809 training accuracy:  0.970117807\n",
      "epoch:  6 step:  320 training loss:  0.0242109671 training accuracy:  0.97018373\n",
      "epoch:  6 step:  330 training loss:  0.0191986952 training accuracy:  0.970249236\n",
      "epoch:  6 step:  340 training loss:  0.021961445 training accuracy:  0.970332325\n",
      "epoch:  6 step:  350 training loss:  0.0283477791 training accuracy:  0.970397\n",
      "epoch:  6 step:  360 training loss:  0.0190866776 training accuracy:  0.970461309\n",
      "epoch:  6 step:  370 training loss:  0.0106194057 training accuracy:  0.970516324\n",
      "epoch:  6 step:  380 training loss:  0.0312709734 training accuracy:  0.970553279\n",
      "epoch:  6 step:  390 training loss:  0.0269361194 training accuracy:  0.970610619\n",
      "epoch:  6 step:  400 training loss:  0.0108685549 training accuracy:  0.97066766\n",
      "epoch:  6 step:  410 training loss:  0.0136810932 training accuracy:  0.970724344\n",
      "epoch:  6 step:  420 training loss:  0.0300023034 training accuracy:  0.970771909\n",
      "epoch:  6 step:  430 training loss:  0.0131382318 training accuracy:  0.970819235\n",
      "epoch:  6 step:  440 training loss:  0.0365340486 training accuracy:  0.970866263\n",
      "epoch:  6 step:  450 training loss:  0.0279229823 training accuracy:  0.970924616\n",
      "epoch:  6 step:  460 training loss:  0.00121191156 training accuracy:  0.970997095\n",
      "epoch:  6 step:  470 training loss:  0.0516047254 training accuracy:  0.971057653\n",
      "epoch:  6 step:  480 training loss:  0.0524697788 training accuracy:  0.971120715\n",
      "epoch:  6 step:  490 training loss:  0.00296018203 training accuracy:  0.971180499\n",
      "epoch:  6 step:  500 training loss:  0.00894089881 training accuracy:  0.971242845\n",
      "epoch:  6 step:  510 training loss:  0.0082364371 training accuracy:  0.971290588\n",
      "epoch:  6 step:  520 training loss:  0.0385264382 training accuracy:  0.971357942\n",
      "epoch:  6 step:  530 training loss:  0.0117905829 training accuracy:  0.971413612\n",
      "epoch:  6 step:  540 training loss:  0.0287117679 training accuracy:  0.971463263\n",
      "epoch:  6 step:  550 training loss:  0.0137910163 training accuracy:  0.971515477\n",
      "epoch:  6 step:  560 training loss:  0.0236084312 training accuracy:  0.971553385\n",
      "epoch:  6 step:  570 training loss:  0.0171901435 training accuracy:  0.971577048\n",
      "epoch:  6 step:  580 training loss:  0.0728324428 training accuracy:  0.971625686\n",
      "epoch:  6 step:  590 training loss:  0.0192216318 training accuracy:  0.971679688\n",
      "epoch:  6 step:  600 training loss:  0.0471973792 training accuracy:  0.971727788\n",
      "epoch:  7 step:  10 training loss:  0.0374536067 training accuracy:  0.971783936\n",
      "epoch:  7 step:  20 training loss:  0.00686017238 training accuracy:  0.971842527\n",
      "epoch:  7 step:  30 training loss:  0.0214518849 training accuracy:  0.971903563\n",
      "epoch:  7 step:  40 training loss:  0.0515970103 training accuracy:  0.971969783\n",
      "epoch:  7 step:  50 training loss:  0.0201735441 training accuracy:  0.972035587\n",
      "epoch:  7 step:  60 training loss:  0.00520082377 training accuracy:  0.972087443\n",
      "epoch:  7 step:  70 training loss:  0.0169371758 training accuracy:  0.972141683\n",
      "epoch:  7 step:  80 training loss:  0.00204893923 training accuracy:  0.972206533\n",
      "epoch:  7 step:  90 training loss:  0.0126735745 training accuracy:  0.972273707\n",
      "epoch:  7 step:  100 training loss:  0.00719714165 training accuracy:  0.97233516\n",
      "epoch:  7 step:  110 training loss:  0.036088787 training accuracy:  0.972385466\n",
      "epoch:  7 step:  120 training loss:  0.00256728381 training accuracy:  0.972440839\n",
      "epoch:  7 step:  130 training loss:  0.00497681228 training accuracy:  0.972506702\n",
      "epoch:  7 step:  140 training loss:  0.00581168663 training accuracy:  0.972569525\n",
      "epoch:  7 step:  150 training loss:  0.0025051611 training accuracy:  0.972629309\n",
      "epoch:  7 step:  160 training loss:  0.00387686677 training accuracy:  0.972691476\n",
      "epoch:  7 step:  170 training loss:  0.00951023 training accuracy:  0.972748\n",
      "epoch:  7 step:  180 training loss:  0.00648761168 training accuracy:  0.972793639\n",
      "epoch:  7 step:  190 training loss:  0.00729739107 training accuracy:  0.97285223\n",
      "epoch:  7 step:  200 training loss:  0.011463332 training accuracy:  0.972910523\n",
      "epoch:  7 step:  210 training loss:  0.0114340708 training accuracy:  0.972958\n",
      "epoch:  7 step:  220 training loss:  0.00449705729 training accuracy:  0.973005235\n",
      "epoch:  7 step:  230 training loss:  0.0243071802 training accuracy:  0.973049581\n",
      "epoch:  7 step:  240 training loss:  0.0187156983 training accuracy:  0.973106742\n",
      "epoch:  7 step:  250 training loss:  0.00643506413 training accuracy:  0.973161042\n",
      "epoch:  7 step:  260 training loss:  0.0379376598 training accuracy:  0.973191738\n",
      "epoch:  7 step:  270 training loss:  0.0934632942 training accuracy:  0.973227382\n",
      "epoch:  7 step:  280 training loss:  0.023451943 training accuracy:  0.973262906\n",
      "epoch:  7 step:  290 training loss:  0.0151493391 training accuracy:  0.973305941\n",
      "epoch:  7 step:  300 training loss:  0.0314144641 training accuracy:  0.973348737\n",
      "epoch:  7 step:  310 training loss:  0.0171765108 training accuracy:  0.973401546\n",
      "epoch:  7 step:  320 training loss:  0.0419164225 training accuracy:  0.973449\n",
      "epoch:  7 step:  330 training loss:  0.0456061885 training accuracy:  0.973498702\n",
      "epoch:  7 step:  340 training loss:  0.00792088453 training accuracy:  0.973545671\n",
      "epoch:  7 step:  350 training loss:  0.0557083935 training accuracy:  0.973597467\n",
      "epoch:  7 step:  360 training loss:  0.0649581924 training accuracy:  0.973648965\n",
      "epoch:  7 step:  370 training loss:  0.0083948886 training accuracy:  0.973687649\n",
      "epoch:  7 step:  380 training loss:  0.0658722371 training accuracy:  0.973728657\n",
      "epoch:  7 step:  390 training loss:  0.0842290893 training accuracy:  0.97376442\n",
      "epoch:  7 step:  400 training loss:  0.0231940523 training accuracy:  0.973807514\n",
      "epoch:  7 step:  410 training loss:  0.0320723765 training accuracy:  0.973835409\n",
      "epoch:  7 step:  420 training loss:  0.01956998 training accuracy:  0.973863184\n",
      "epoch:  7 step:  430 training loss:  0.0257928856 training accuracy:  0.973890841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  7 step:  440 training loss:  0.011106045 training accuracy:  0.973928213\n",
      "epoch:  7 step:  450 training loss:  0.00730133476 training accuracy:  0.97396791\n",
      "epoch:  7 step:  460 training loss:  0.00946734473 training accuracy:  0.974007368\n",
      "epoch:  7 step:  470 training loss:  0.00944985729 training accuracy:  0.974056482\n",
      "epoch:  7 step:  480 training loss:  0.00998330861 training accuracy:  0.974105418\n",
      "epoch:  7 step:  490 training loss:  0.0774801522 training accuracy:  0.974146724\n",
      "epoch:  7 step:  500 training loss:  0.00148397451 training accuracy:  0.974192679\n",
      "epoch:  7 step:  510 training loss:  0.0232252628 training accuracy:  0.97422874\n",
      "epoch:  7 step:  520 training loss:  0.00733581651 training accuracy:  0.974245131\n",
      "epoch:  7 step:  530 training loss:  0.0403766967 training accuracy:  0.974273622\n",
      "epoch:  7 step:  540 training loss:  0.00806467608 training accuracy:  0.974314034\n",
      "epoch:  7 step:  550 training loss:  0.00767880306 training accuracy:  0.974356651\n",
      "epoch:  7 step:  560 training loss:  0.0400959402 training accuracy:  0.974396646\n",
      "epoch:  7 step:  570 training loss:  0.057236325 training accuracy:  0.974426866\n",
      "epoch:  7 step:  580 training loss:  0.0167909935 training accuracy:  0.974468887\n",
      "epoch:  7 step:  590 training loss:  0.0120049873 training accuracy:  0.974510729\n",
      "epoch:  7 step:  600 training loss:  0.0300977919 training accuracy:  0.974552393\n",
      "epoch:  8 step:  10 training loss:  0.00663859583 training accuracy:  0.974601\n",
      "epoch:  8 step:  20 training loss:  0.00282826205 training accuracy:  0.97463268\n",
      "epoch:  8 step:  30 training loss:  0.0507320128 training accuracy:  0.974673748\n",
      "epoch:  8 step:  40 training loss:  0.0457325131 training accuracy:  0.974719346\n",
      "epoch:  8 step:  50 training loss:  0.0114926575 training accuracy:  0.974755287\n",
      "epoch:  8 step:  60 training loss:  0.0267712921 training accuracy:  0.974795759\n",
      "epoch:  8 step:  70 training loss:  0.0565291308 training accuracy:  0.974836051\n",
      "epoch:  8 step:  80 training loss:  0.0115987454 training accuracy:  0.974871516\n",
      "epoch:  8 step:  90 training loss:  0.0781869814 training accuracy:  0.974888086\n",
      "epoch:  8 step:  100 training loss:  0.0263097622 training accuracy:  0.974927902\n",
      "epoch:  8 step:  110 training loss:  0.0228316523 training accuracy:  0.97496289\n",
      "epoch:  8 step:  120 training loss:  0.112061135 training accuracy:  0.974990726\n",
      "epoch:  8 step:  130 training loss:  0.0207450371 training accuracy:  0.975041568\n",
      "epoch:  8 step:  140 training loss:  0.00163889886 training accuracy:  0.975073755\n",
      "epoch:  8 step:  150 training loss:  0.00231545558 training accuracy:  0.975124121\n",
      "epoch:  8 step:  160 training loss:  0.00200410839 training accuracy:  0.975169718\n",
      "epoch:  8 step:  170 training loss:  0.0163555536 training accuracy:  0.975215077\n",
      "epoch:  8 step:  180 training loss:  0.00731121656 training accuracy:  0.975262582\n",
      "epoch:  8 step:  190 training loss:  0.0152232321 training accuracy:  0.975293875\n",
      "epoch:  8 step:  200 training loss:  0.00237551751 training accuracy:  0.975340903\n",
      "epoch:  8 step:  210 training loss:  0.0571965948 training accuracy:  0.975383222\n",
      "epoch:  8 step:  220 training loss:  0.0145762516 training accuracy:  0.975425363\n",
      "epoch:  8 step:  230 training loss:  0.00980593637 training accuracy:  0.975467265\n",
      "epoch:  8 step:  240 training loss:  0.0117094563 training accuracy:  0.975491\n",
      "epoch:  8 step:  250 training loss:  0.0739971474 training accuracy:  0.975523591\n",
      "epoch:  8 step:  260 training loss:  0.00934879761 training accuracy:  0.975556076\n",
      "epoch:  8 step:  270 training loss:  0.00925136637 training accuracy:  0.975599527\n",
      "epoch:  8 step:  280 training loss:  0.0109209726 training accuracy:  0.975625\n",
      "epoch:  8 step:  290 training loss:  0.0159657914 training accuracy:  0.975665927\n",
      "epoch:  8 step:  300 training loss:  0.0827058479 training accuracy:  0.975688875\n",
      "epoch:  8 step:  310 training loss:  0.00457914872 training accuracy:  0.975729465\n",
      "epoch:  8 step:  320 training loss:  0.0125556216 training accuracy:  0.975769937\n",
      "epoch:  8 step:  330 training loss:  0.00808422174 training accuracy:  0.97581017\n",
      "epoch:  8 step:  340 training loss:  0.00932350289 training accuracy:  0.975850224\n",
      "epoch:  8 step:  350 training loss:  0.0087384386 training accuracy:  0.975892305\n",
      "epoch:  8 step:  360 training loss:  0.0505148508 training accuracy:  0.975932\n",
      "epoch:  8 step:  370 training loss:  0.0118066613 training accuracy:  0.97597158\n",
      "epoch:  8 step:  380 training loss:  0.0302744936 training accuracy:  0.976010919\n",
      "epoch:  8 step:  390 training loss:  0.0165610723 training accuracy:  0.976045728\n",
      "epoch:  8 step:  400 training loss:  0.00477677956 training accuracy:  0.976084769\n",
      "epoch:  8 step:  410 training loss:  0.0135000637 training accuracy:  0.976115\n",
      "epoch:  8 step:  420 training loss:  0.0191914868 training accuracy:  0.976147175\n",
      "epoch:  8 step:  430 training loss:  0.0797698125 training accuracy:  0.976170599\n",
      "epoch:  8 step:  440 training loss:  0.0123183914 training accuracy:  0.976185322\n",
      "epoch:  8 step:  450 training loss:  0.0189125482 training accuracy:  0.97621721\n",
      "epoch:  8 step:  460 training loss:  0.0383430198 training accuracy:  0.976231754\n",
      "epoch:  8 step:  470 training loss:  0.00887844246 training accuracy:  0.976256967\n",
      "epoch:  8 step:  480 training loss:  0.0110289147 training accuracy:  0.976277769\n",
      "epoch:  8 step:  490 training loss:  0.0160002112 training accuracy:  0.976275\n",
      "epoch:  8 step:  500 training loss:  0.091906175 training accuracy:  0.976291478\n",
      "epoch:  8 step:  510 training loss:  0.0733035579 training accuracy:  0.976324856\n",
      "epoch:  8 step:  520 training loss:  0.0955576897 training accuracy:  0.976347446\n",
      "epoch:  8 step:  530 training loss:  0.0196188223 training accuracy:  0.97637\n",
      "epoch:  8 step:  540 training loss:  0.0703006685 training accuracy:  0.97639662\n",
      "epoch:  8 step:  550 training loss:  0.00459129224 training accuracy:  0.976416826\n",
      "epoch:  8 step:  560 training loss:  0.0384073555 training accuracy:  0.976449609\n",
      "epoch:  8 step:  570 training loss:  0.0235087425 training accuracy:  0.976478\n",
      "epoch:  8 step:  580 training loss:  0.0299440976 training accuracy:  0.976495802\n",
      "epoch:  8 step:  590 training loss:  0.0100043453 training accuracy:  0.976528168\n",
      "epoch:  8 step:  600 training loss:  0.0276831239 training accuracy:  0.976564586\n",
      "epoch:  9 step:  10 training loss:  0.0142967952 training accuracy:  0.976607084\n",
      "epoch:  9 step:  20 training loss:  0.00352576608 training accuracy:  0.976645231\n",
      "epoch:  9 step:  30 training loss:  0.00940355565 training accuracy:  0.976681173\n",
      "epoch:  9 step:  40 training loss:  0.0367448479 training accuracy:  0.976716936\n",
      "epoch:  9 step:  50 training loss:  0.00399162108 training accuracy:  0.976752579\n",
      "epoch:  9 step:  60 training loss:  0.0274227 training accuracy:  0.976781905\n",
      "epoch:  9 step:  70 training loss:  0.000836267893 training accuracy:  0.976825476\n",
      "epoch:  9 step:  80 training loss:  0.0131060481 training accuracy:  0.976860642\n",
      "epoch:  9 step:  90 training loss:  0.0566168167 training accuracy:  0.976899803\n",
      "epoch:  9 step:  100 training loss:  0.0074335509 training accuracy:  0.976940811\n",
      "epoch:  9 step:  110 training loss:  0.00514705898 training accuracy:  0.976985753\n",
      "epoch:  9 step:  120 training loss:  0.067182593 training accuracy:  0.97702843\n",
      "epoch:  9 step:  130 training loss:  0.010313333 training accuracy:  0.977071\n",
      "epoch:  9 step:  140 training loss:  0.00340953493 training accuracy:  0.97710526\n",
      "epoch:  9 step:  150 training loss:  0.0453776978 training accuracy:  0.977139413\n",
      "epoch:  9 step:  160 training loss:  0.0177261643 training accuracy:  0.977169335\n",
      "epoch:  9 step:  170 training loss:  0.0119880531 training accuracy:  0.97720319\n",
      "epoch:  9 step:  180 training loss:  0.00462992443 training accuracy:  0.97723496\n",
      "epoch:  9 step:  190 training loss:  0.00287869549 training accuracy:  0.97726655\n",
      "epoch:  9 step:  200 training loss:  0.000668877503 training accuracy:  0.977302\n",
      "epoch:  9 step:  210 training loss:  0.00188163249 training accuracy:  0.977341294\n",
      "epoch:  9 step:  220 training loss:  0.0451189801 training accuracy:  0.977370501\n",
      "epoch:  9 step:  230 training loss:  0.00318765081 training accuracy:  0.977401614\n",
      "epoch:  9 step:  240 training loss:  0.00378452661 training accuracy:  0.977432549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  9 step:  250 training loss:  0.0529522076 training accuracy:  0.977459431\n",
      "epoch:  9 step:  260 training loss:  0.0215214156 training accuracy:  0.977496\n",
      "epoch:  9 step:  270 training loss:  0.00275702844 training accuracy:  0.977522671\n",
      "epoch:  9 step:  280 training loss:  0.012729777 training accuracy:  0.977555096\n",
      "epoch:  9 step:  290 training loss:  0.00263827224 training accuracy:  0.977585435\n",
      "epoch:  9 step:  300 training loss:  0.000374119874 training accuracy:  0.97761178\n",
      "epoch:  9 step:  310 training loss:  0.0192162376 training accuracy:  0.977649689\n",
      "epoch:  9 step:  320 training loss:  0.0025310833 training accuracy:  0.977683604\n",
      "epoch:  9 step:  330 training loss:  0.0779746622 training accuracy:  0.977715373\n",
      "epoch:  9 step:  340 training loss:  0.00616634591 training accuracy:  0.97774905\n",
      "epoch:  9 step:  350 training loss:  0.00641707657 training accuracy:  0.977784455\n",
      "epoch:  9 step:  360 training loss:  0.0280789118 training accuracy:  0.977808118\n",
      "epoch:  9 step:  370 training loss:  0.0148822879 training accuracy:  0.977833629\n",
      "epoch:  9 step:  380 training loss:  0.000880261883 training accuracy:  0.977861\n",
      "epoch:  9 step:  390 training loss:  0.00800345279 training accuracy:  0.977888227\n",
      "epoch:  9 step:  400 training loss:  0.0203174241 training accuracy:  0.977919221\n",
      "epoch:  9 step:  410 training loss:  0.00431681052 training accuracy:  0.977950096\n",
      "epoch:  9 step:  420 training loss:  0.0195311978 training accuracy:  0.977977037\n",
      "epoch:  9 step:  430 training loss:  0.00310461945 training accuracy:  0.978005707\n",
      "epoch:  9 step:  440 training loss:  0.00255434983 training accuracy:  0.978040099\n",
      "epoch:  9 step:  450 training loss:  0.00668052118 training accuracy:  0.978066683\n",
      "epoch:  9 step:  460 training loss:  0.00613697153 training accuracy:  0.978093147\n",
      "epoch:  9 step:  470 training loss:  0.00423097378 training accuracy:  0.978121459\n",
      "epoch:  9 step:  480 training loss:  0.00590265589 training accuracy:  0.978145838\n",
      "epoch:  9 step:  490 training loss:  0.00400518626 training accuracy:  0.978177667\n",
      "epoch:  9 step:  500 training loss:  0.0125289587 training accuracy:  0.978209436\n",
      "epoch:  9 step:  510 training loss:  0.00268798834 training accuracy:  0.978244841\n",
      "epoch:  9 step:  520 training loss:  0.00596475601 training accuracy:  0.978282\n",
      "epoch:  9 step:  530 training loss:  0.00864622928 training accuracy:  0.978315175\n",
      "epoch:  9 step:  540 training loss:  0.0142370546 training accuracy:  0.97834456\n",
      "epoch:  9 step:  550 training loss:  0.00198588 training accuracy:  0.978373826\n",
      "epoch:  9 step:  560 training loss:  0.0225555636 training accuracy:  0.978403\n",
      "epoch:  9 step:  570 training loss:  0.0670246184 training accuracy:  0.978426456\n",
      "epoch:  9 step:  580 training loss:  0.0314783044 training accuracy:  0.978457272\n",
      "epoch:  9 step:  590 training loss:  0.0024983061 training accuracy:  0.978480518\n",
      "epoch:  9 step:  600 training loss:  0.0144408932 training accuracy:  0.978512943\n",
      "epoch:  10 step:  10 training loss:  0.0474397056 training accuracy:  0.978541613\n",
      "epoch:  10 step:  20 training loss:  0.00327001233 training accuracy:  0.978571951\n",
      "epoch:  10 step:  30 training loss:  0.00784227625 training accuracy:  0.978598535\n",
      "epoch:  10 step:  40 training loss:  0.00255472842 training accuracy:  0.978628695\n",
      "epoch:  10 step:  50 training loss:  0.00370214647 training accuracy:  0.978653193\n",
      "epoch:  10 step:  60 training loss:  0.00933815911 training accuracy:  0.978688657\n",
      "epoch:  10 step:  70 training loss:  0.021630466 training accuracy:  0.97871846\n",
      "epoch:  10 step:  80 training loss:  0.0256213397 training accuracy:  0.978751838\n",
      "epoch:  10 step:  90 training loss:  0.00669602165 training accuracy:  0.978786886\n",
      "epoch:  10 step:  100 training loss:  0.0168346558 training accuracy:  0.97881639\n",
      "epoch:  10 step:  110 training loss:  0.00410929974 training accuracy:  0.978847563\n",
      "epoch:  10 step:  120 training loss:  0.011543503 training accuracy:  0.978876829\n",
      "epoch:  10 step:  130 training loss:  0.00313559524 training accuracy:  0.9789114\n",
      "epoch:  10 step:  140 training loss:  0.00174478325 training accuracy:  0.978944063\n",
      "epoch:  10 step:  150 training loss:  0.00389230577 training accuracy:  0.978973\n",
      "epoch:  10 step:  160 training loss:  0.0292456672 training accuracy:  0.97900182\n",
      "epoch:  10 step:  170 training loss:  0.0212908313 training accuracy:  0.979034126\n",
      "epoch:  10 step:  180 training loss:  0.0418785587 training accuracy:  0.97905916\n",
      "epoch:  10 step:  190 training loss:  0.0120776799 training accuracy:  0.979089439\n",
      "epoch:  10 step:  200 training loss:  0.0041227336 training accuracy:  0.979123235\n",
      "epoch:  10 step:  210 training loss:  0.13703157 training accuracy:  0.979148\n",
      "epoch:  10 step:  220 training loss:  0.0160828717 training accuracy:  0.979174376\n",
      "epoch:  10 step:  230 training loss:  0.00563891232 training accuracy:  0.979198933\n",
      "epoch:  10 step:  240 training loss:  0.00845435 training accuracy:  0.979228735\n",
      "epoch:  10 step:  250 training loss:  0.00317079294 training accuracy:  0.979254842\n",
      "epoch:  10 step:  260 training loss:  0.0130249057 training accuracy:  0.979286194\n",
      "epoch:  10 step:  270 training loss:  0.00367814279 training accuracy:  0.979317486\n",
      "epoch:  10 step:  280 training loss:  0.000582916429 training accuracy:  0.979345083\n",
      "epoch:  10 step:  290 training loss:  0.0132305631 training accuracy:  0.979374349\n",
      "epoch:  10 step:  300 training loss:  0.0101671033 training accuracy:  0.9794\n",
      "epoch:  10 step:  310 training loss:  0.0071896906 training accuracy:  0.979430795\n",
      "epoch:  10 step:  320 training loss:  0.00512900064 training accuracy:  0.979458034\n",
      "epoch:  10 step:  330 training loss:  0.0104684504 training accuracy:  0.979493916\n",
      "epoch:  10 step:  340 training loss:  0.000410713605 training accuracy:  0.9795174\n",
      "epoch:  10 step:  350 training loss:  0.0698227435 training accuracy:  0.97954607\n",
      "epoch:  10 step:  360 training loss:  0.0108575402 training accuracy:  0.979572892\n",
      "epoch:  10 step:  370 training loss:  0.00142380118 training accuracy:  0.979601383\n",
      "epoch:  10 step:  380 training loss:  0.0432647131 training accuracy:  0.979624569\n",
      "epoch:  10 step:  390 training loss:  0.00541229825 training accuracy:  0.979651093\n",
      "epoch:  10 step:  400 training loss:  0.0458094589 training accuracy:  0.97967416\n",
      "epoch:  10 step:  410 training loss:  0.0114692114 training accuracy:  0.979700506\n",
      "epoch:  10 step:  420 training loss:  0.00725477887 training accuracy:  0.979718208\n",
      "epoch:  10 step:  430 training loss:  0.0124190198 training accuracy:  0.979741\n",
      "epoch:  10 step:  440 training loss:  0.0485346131 training accuracy:  0.979756832\n",
      "epoch:  10 step:  450 training loss:  0.060768161 training accuracy:  0.979770958\n",
      "epoch:  10 step:  460 training loss:  0.0246112701 training accuracy:  0.979793489\n",
      "epoch:  10 step:  470 training loss:  0.00961266831 training accuracy:  0.979810894\n",
      "epoch:  10 step:  480 training loss:  0.00196659961 training accuracy:  0.979828238\n",
      "epoch:  10 step:  490 training loss:  0.00541858748 training accuracy:  0.979848921\n",
      "epoch:  10 step:  500 training loss:  0.0563517846 training accuracy:  0.979871213\n",
      "epoch:  10 step:  510 training loss:  0.0679366961 training accuracy:  0.97988832\n",
      "epoch:  10 step:  520 training loss:  0.00301281456 training accuracy:  0.979913831\n",
      "epoch:  10 step:  530 training loss:  0.0236929413 training accuracy:  0.979935944\n",
      "epoch:  10 step:  540 training loss:  0.00877082 training accuracy:  0.979957938\n",
      "epoch:  10 step:  550 training loss:  0.047535453 training accuracy:  0.979971409\n",
      "epoch:  10 step:  560 training loss:  0.016355738 training accuracy:  0.979991615\n",
      "epoch:  10 step:  570 training loss:  0.00386561104 training accuracy:  0.980006695\n",
      "epoch:  10 step:  580 training loss:  0.0581341535 training accuracy:  0.98002845\n",
      "epoch:  10 step:  590 training loss:  0.0454172082 training accuracy:  0.980050087\n",
      "epoch:  10 step:  600 training loss:  0.0283728056 training accuracy:  0.980066657\n",
      "final step:600 final loss:0.028372805565595627 accuracy:0.9800666570663452\n"
     ]
    }
   ],
   "source": [
    "step, training_loss, train_accuracy = training(model, optimizer)\n",
    "print(\"final step:{} final loss:{} accuracy:{}\".format(step, training_loss, accuracy.result()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- #### 并不是所有的都支持AutoGraph模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "## 加载数据--方式2：批量读入数据\n",
    "def read_data():\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "    print(\"mnist traing data shape: \", x_train.shape)\n",
    "    print(\"mnist test data shape: \", x_test.shape)\n",
    "    x_train = tf.cast(x_train, tf.float32) / 255.0\n",
    "    y_train = tf.cast(y_train, tf.int64)\n",
    "    def get_batch():\n",
    "        batch_size = 100\n",
    "        batch_num = int(x_train.shape[0] // batch_size)\n",
    "        for i in range(batch_num):\n",
    "            batch_x = x_train[i * batch_size: (i+1) * batch_size, :, :]\n",
    "            batch_y = y_train[i * batch_size: (i+1) * batch_size]\n",
    "            yield batch_x, batch_y\n",
    "    data = tf.data.Dataset.from_generator(get_batch, (tf.float32, tf.int64)) ## \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 定义多层感知机模型\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Reshape(target_shape=(28 * 28,), input_shape=(28, 28)))\n",
    "model.add(tf.keras.layers.Dense(200, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(100, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "model.build()\n",
    "## 定义优化器\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "### 定义loss\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "### 定义准确率\n",
    "accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "### 定义梯度优化\n",
    "def one_step_gradient(model, optimizer, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = model(x)\n",
    "        lossing = loss(y, logits)\n",
    "    ## 梯度\n",
    "    grads = tape.gradient(lossing, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    ## predict\n",
    "    predict = tf.nn.softmax(logits) ### 这个softmax到底需要不需要\n",
    "    accuracy(y, predict)\n",
    "    return lossing\n",
    "\n",
    "def training(model, optimizer):\n",
    "    ## 加载数据集\n",
    "    # train_data = read_mnist()\n",
    "    train_data = read_data()\n",
    "    epoches = 10\n",
    "    training_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "    for epoch in range(epoches):\n",
    "        step = 0\n",
    "        for batch_x, batch_y in train_data:\n",
    "            step += 1\n",
    "            training_loss = one_step_gradient(model, optimizer, batch_x, batch_y)\n",
    "            if step % 100 == 0:\n",
    "                tf.print(\"epoch: \",epoch + 1, \"step: \", step, \"training loss: \", training_loss, \n",
    "                         \"training accuracy: \",accuracy.result())\n",
    "    return step, training_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnist traing data shape:  (60000, 28, 28)\n",
      "mnist test data shape:  (10000, 28, 28)\n",
      "epoch:  1 step:  100 training loss:  0.193819642 training accuracy:  0.7991\n",
      "epoch:  1 step:  200 training loss:  0.206223711 training accuracy:  0.854\n",
      "epoch:  1 step:  300 training loss:  0.321686298 training accuracy:  0.88076669\n",
      "epoch:  1 step:  400 training loss:  0.287481755 training accuracy:  0.89515\n",
      "epoch:  1 step:  500 training loss:  0.214030355 training accuracy:  0.90436\n",
      "epoch:  1 step:  600 training loss:  0.200359613 training accuracy:  0.913683355\n",
      "epoch:  2 step:  100 training loss:  0.0579241738 training accuracy:  0.9206\n",
      "epoch:  2 step:  200 training loss:  0.0396165289 training accuracy:  0.92605\n",
      "epoch:  2 step:  300 training loss:  0.126213253 training accuracy:  0.93032223\n",
      "epoch:  2 step:  400 training loss:  0.131759942 training accuracy:  0.93414\n",
      "epoch:  2 step:  500 training loss:  0.111321948 training accuracy:  0.9371\n",
      "epoch:  2 step:  600 training loss:  0.187709063 training accuracy:  0.940283358\n",
      "epoch:  3 step:  100 training loss:  0.0301663876 training accuracy:  0.943107665\n",
      "epoch:  3 step:  200 training loss:  0.0271576494 training accuracy:  0.945528567\n",
      "epoch:  3 step:  300 training loss:  0.0582095832 training accuracy:  0.94764\n",
      "epoch:  3 step:  400 training loss:  0.0463915877 training accuracy:  0.949587524\n",
      "epoch:  3 step:  500 training loss:  0.0508674867 training accuracy:  0.951294124\n",
      "epoch:  3 step:  600 training loss:  0.200745165 training accuracy:  0.953077793\n",
      "epoch:  4 step:  100 training loss:  0.023161605 training accuracy:  0.954673707\n",
      "epoch:  4 step:  200 training loss:  0.0419942 training accuracy:  0.95606\n",
      "epoch:  4 step:  300 training loss:  0.038789954 training accuracy:  0.957390487\n",
      "epoch:  4 step:  400 training loss:  0.0295646526 training accuracy:  0.958563626\n",
      "epoch:  4 step:  500 training loss:  0.0265873615 training accuracy:  0.959613\n",
      "epoch:  4 step:  600 training loss:  0.173567832 training accuracy:  0.960787475\n",
      "epoch:  5 step:  100 training loss:  0.0211396553 training accuracy:  0.96186\n",
      "epoch:  5 step:  200 training loss:  0.017904127 training accuracy:  0.962938488\n",
      "epoch:  5 step:  300 training loss:  0.020635264 training accuracy:  0.963829637\n",
      "epoch:  5 step:  400 training loss:  0.0273914114 training accuracy:  0.964646399\n",
      "epoch:  5 step:  500 training loss:  0.0338792 training accuracy:  0.965334475\n",
      "epoch:  5 step:  600 training loss:  0.156825155 training accuracy:  0.96612668\n",
      "epoch:  6 step:  100 training loss:  0.017162066 training accuracy:  0.966841936\n",
      "epoch:  6 step:  200 training loss:  0.0133940103 training accuracy:  0.967471898\n",
      "epoch:  6 step:  300 training loss:  0.0159640461 training accuracy:  0.968078792\n",
      "epoch:  6 step:  400 training loss:  0.0185661465 training accuracy:  0.968723536\n",
      "epoch:  6 step:  500 training loss:  0.0243612938 training accuracy:  0.969314277\n",
      "epoch:  6 step:  600 training loss:  0.121734545 training accuracy:  0.969927788\n",
      "epoch:  7 step:  100 training loss:  0.00475051673 training accuracy:  0.970491886\n",
      "epoch:  7 step:  200 training loss:  0.0423544757 training accuracy:  0.971031606\n",
      "epoch:  7 step:  300 training loss:  0.00666787149 training accuracy:  0.971538484\n",
      "epoch:  7 step:  400 training loss:  0.00778140267 training accuracy:  0.972027481\n",
      "epoch:  7 step:  500 training loss:  0.0271152239 training accuracy:  0.972485363\n",
      "epoch:  7 step:  600 training loss:  0.133316711 training accuracy:  0.972973824\n",
      "epoch:  8 step:  100 training loss:  0.00667077489 training accuracy:  0.973379076\n",
      "epoch:  8 step:  200 training loss:  0.074869588 training accuracy:  0.973856807\n",
      "epoch:  8 step:  300 training loss:  0.0105126416 training accuracy:  0.974233329\n",
      "epoch:  8 step:  400 training loss:  0.0181776565 training accuracy:  0.974621713\n",
      "epoch:  8 step:  500 training loss:  0.0116788922 training accuracy:  0.975012779\n",
      "epoch:  8 step:  600 training loss:  0.123389 training accuracy:  0.975422919\n",
      "epoch:  9 step:  100 training loss:  0.00442879368 training accuracy:  0.975738764\n",
      "epoch:  9 step:  200 training loss:  0.0592362769 training accuracy:  0.976016\n",
      "epoch:  9 step:  300 training loss:  0.0704743415 training accuracy:  0.97633332\n",
      "epoch:  9 step:  400 training loss:  0.0171594918 training accuracy:  0.976640403\n",
      "epoch:  9 step:  500 training loss:  0.0723906159 training accuracy:  0.976935863\n",
      "epoch:  9 step:  600 training loss:  0.0958478451 training accuracy:  0.977242589\n",
      "epoch:  10 step:  100 training loss:  0.0013302752 training accuracy:  0.97753638\n",
      "epoch:  10 step:  200 training loss:  0.0158517454 training accuracy:  0.977842867\n",
      "epoch:  10 step:  300 training loss:  0.002938702 training accuracy:  0.978105247\n",
      "epoch:  10 step:  400 training loss:  0.0157114137 training accuracy:  0.978367269\n",
      "epoch:  10 step:  500 training loss:  0.0390234143 training accuracy:  0.97864747\n",
      "epoch:  10 step:  600 training loss:  0.170312464 training accuracy:  0.97889334\n",
      "final step:600 final loss:0.17031246423721313 accuracy:0.9788933396339417\n"
     ]
    }
   ],
   "source": [
    "step, training_loss, train_accuracy = training(model, optimizer)\n",
    "print(\"final step:{} final loss:{} accuracy:{}\".format(step, training_loss, accuracy.result()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
